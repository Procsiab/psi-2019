%! TEX root = main.tex
% Capitolo 6

\chapter{Verifica d'ipotesi}
    \section{Ipotesi statistica}
        \begin{defn}
            Data una popolazione con distribuzione con distribuzione $F_\vartheta$ determinata da un o più 
            parametri incogniti $\vec{\vartheta}$, chiamiamo \emph{ipotesi statistica} un'affermazione 
            su un o più parametri della popolazione.

            Se scegliamo $\vartheta \in \Theta_0 \subset \Theta$ e indichiamo con $\Theta$ lo spazio dei 
            parametri, allora indichiamo l'\emph{ipotesi nulla} come: \[
                H_0 \,:\, \vartheta \in \Theta_0
            ;\] se $\Theta_0$ si riduce a un punto abbiamo un'ipotesi semplice, altrimenti diremo che essa 
            è composta.

            Indichiamo la negazione dell'ipotesi semplice tramite: \[
                H_1 \,:\, \vartheta \in \Theta_1
            ,\] dove abbiamo indicato il complementare dello spazio dei campioni tramite 
            $\Theta_1 \coloneqq \Theta\backslash \Theta_0$, e la chiamiamo \emph{ipotesi alternativa}.
        \end{defn}
    \section{Test}
        \begin{defn}[Verifica d'ipotesi]
            Supponiamo di avere una popolazione con distribuzione $F_\vartheta$ dipendente dal parametro 
            incognito $\vartheta$, e vogliamo verificare l'ipotesi nulla $H_0$ sulla distribuzione.
            Un \emph{test per la verifica dell'ipotesi} $H_0$ è la procedura che permette di determinare se 
            i valori di un campione aleatorio sono compatibili con l'ipotesi formulata: in caso affermativo 
            \emph{accettiamo} l'ipotesi introdotta, altrimenti la \emph{rifiutiamo}.
        \end{defn}
        \begin{note}
            Accettare un'ipotesi non significa assumere che essa sia vera, ma vuol dire che basandoci sui 
            dati a disposizione non possiamo escluderla.
        \end{note}
        \begin{defn}[Regione critica]
            Sia dato un campione aleatorio $X_1,\, \ldots,\, X_{n} = \vec{X}$ estratto da una popolazione sulla 
            quale formuliamo un test con ipotesi nulla $H_0$; chiamiamo \emph{regione critica} e la indichiamo 
            tramite $C \subseteq \mathbb{R}^n$ la regione dello spazio $n$\nbdash dimensionale che determina 
            \underline{il rifiuto dell'ipotesi nulla}, in presenza della realizzazione $\vec{X} = \vec{x}$:
            \begin{align*}
                \text{accetto } H_0 & \;\;\; \text{se $\vec{x} \notin C$;} \\
                \text{rifiuto } H_0 & \;\;\; \text{se $\vec{x} \in C$.}
            \end{align*}
        \end{defn}
        \begin{obsv}
            Se vogliamo costruire la regione critica del test per verificare una ipotesi nulla 
            $H_0 \,:\, \vartheta \in \Psi$, allora dovremo individuare uno stimatore puntuale per 
            $\vartheta$, del tipo $d_n(X_1,\, \ldots,\, X_{n})$.

            Quindi, rifiuteremo l'ipotesi nulla quando $d_n(\vec{X})$ è ``lontano'' dall'insieme $\Psi$ dei 
            possibili valori del parametro $\vartheta$.

            La lontananza dello stimatore dall'insieme dei valori per il parametro è determinata dalla
            regione critica del test; quest'ultima può essere ottenuta insieme al livello di significatività 
            $\alpha$ conoscendo la distribuzione dello stimatore $d_n(\vec{X})$ quando $H_0$ è vera.
        \end{obsv}
        \begin{defn}[Errore di test]
            Consideriamo un test d'ipotesi con ipotesi nulla $H_0$; in tal caso possiamo avere solo due tipi 
            di errore:
            \begin{itemize}
                \item commettiamo errore di $\mathbf{I}$ specie quando i dati ci portano a rifiutare $H_0$ 
                    anche se in realtà essa è vera;
                \item commettiamo errore di $\mathbf{II}$ specie quando i dati ci portano ad accettare $H_0$ 
                    anche se in realtà essa è falsa.
            \end{itemize}
            Dato che la verifica di ipotesi mostra la compatibilità dell'ipotesi con i dati a disposizione, 
            l'errore di $\mathbf{I}$ specie è più grave di quello di $\mathbf{II}$ specie.
        \end{defn}
        \subsection{Livello di significatività}
            \begin{defn}
                Consideriamo un test con ipotesi nulla $H_0$; chiamiamo \emph{livello di significatività} la 
                soglia per la probabilità di errore di $\mathbf{I}$ specie, che indichiamo con $\alpha$: \[
                    P(\mathbf{I}\text{ specie}) 
                    = P_\vartheta\big((X_1,\, \ldots,\, X_{n}) \in C\big) \leq \alpha
                .\] La relazione precedente vale per ogni $\vartheta$ che soddisfa 
                $H_0\,:\, \vartheta \in \Theta_0$, inoltre possiamo chiamarla test di regione critica $C$ 
                di livello di significatività $\alpha$.
            \end{defn}
        \subsection{Funzione di potenza}
            \begin{defn}
                Chiamiamo \emph{funzione di potenza} per un test di regione critica $C$ la funzione del 
                parametro incognito $\vartheta$ definita come: \[
                    \pi(\vartheta) \coloneqq P_\vartheta(\vec{X} \in C)
                .\] Se $\vartheta \in \Theta_1$ questa funzione rappresenta la probabilità di prendere la 
                decisione giusta sull'ipotesi; altrimenti, per $\vartheta \in \Theta_0$ la funzione di 
                potenza rappresenta la probabilità di errore di $\mathbf{I}$ specie.
            \end{defn}
            \begin{obsv}[Massima potenza]
                Per costruire un test di livello di significatività $\alpha$ con la potenza massima, data la 
                statistica test $D_n$, imponiamo: \[
                    \alpha = P_{\vartheta_0}(D_n > t)
                ;\] indichiamo la soluzione come $d_{n,\,\alpha}|_{\vartheta=\vartheta_0}$, il quantile di 
                ordine $\alpha$ della distribuzione della statistica test $D_n$ quando $\vartheta=\vartheta_0$.
            \end{obsv}
            \begin{defn}[Curva operativa]
                Chiamiamo \emph{curva operativa} il grafico della seguente funzione, che indica la 
                probabilità di errore di $\mathbf{II}$ specie per $\vartheta \in \Theta_1$: \[
                    \beta(\vartheta) \coloneqq 1 - \pi(\vartheta)
                .\] 
            \end{defn}
            \begin{obsv}
                Per valutare la probabilità di errore di $\mathbf{II}$ specie, dobbiamo calcolare la potenza 
                come funzione del parametro incognito: \[
                    \pi(\vartheta) = P_\vartheta(D_n > d_{n,\,\alpha}|_{\vartheta=\vartheta_0})
                .\]
            \end{obsv}
        \subsection{Ampiezza}
            \begin{defn}
                Chiamiamo \emph{ampiezza} del test o della regione critica l'estremo superiore delle 
                probabilità d'errore di $\mathbf{I}$ specie, e la indichiamo con: \[
                    \alpha_* \coloneqq \sup_{\substack{\vartheta \in \Theta_0}} \pi(\vartheta) 
                    = \sup_{\substack{\vartheta \in \Theta_0}} P_\vartheta(\vec{X} \in C)
                .\] Diremo quindi che un test è di livello di significatività $\alpha$ solo se la sua ampiezza 
                è minore o uguale alla significatività ($\alpha_* \leq \alpha$).
            \end{defn}
        \subsection{Statistica test}
        Consideriamo la statistica $D_n = d-n(X_1,\, \ldots,\, X_{n})$, e definiamo l'intervallo 
        $C(t) = \{\vec{x} \in \mathbb{R}_n \,:\, d_n(\vec{x}) > t\}$; al variare di $t$ otteniamo una famiglia 
        di test statistici, definiti dalla regione critica $C(t)$.

        Allora chiamiamo \emph{statistica test} la statistica $D_n$, e per ogni $t = \bar{t}$ fissiamo 
        un test di regione critica $C(\bar{t})$.
        \subsection{\emph{p}\nbdash value}
            \begin{defn}
                Considerando una famiglia di test al variare del livello di significatività $\alpha$, 
                chiamiamo \emph{p\nbdash value} l'estremo inferiore della significatività per il quale 
                bisognerebbe rifiutare l'ipotesi nulla coi dati a disposizione.
            \end{defn}
            \begin{obsv}
                Sia $\alpha(t)$ l'ampiezza di un test rispetto al parametro $t$ e $d_* = d_n(\vec{x})$ il 
                valore della statistica test $D_n$ nell'esperimento considerato; allora $\alpha(t)$ è 
                una funzione decrescente di $t$, perciò avremo la minore ampiezza compatibile col rifiuto 
                dell'ipotesi nulla per $t = d_*$, quindi il \emph{p}\nbdash value sarà dato da: \[
                    \alpha(d_*) = P_{\vartheta_0}(D_n > d_*)
                .\] 
            \end{obsv}
    \section{Test per media di popolazione normale}
        \subsection{\emph{Z}\nbdash test}
            \begin{defn}[Bilatero]
                Sia $X_1,\, \ldots,\, X_{n}$ un campione aleatorio da una popolazione normale con media $\mu$ 
                incognita e varianza $\sigma^2$ nota; fissata una costante $\mu_0$, vogliamo verificare 
                l'ipotesi nulla seguente contro l'alternativa: \[
                \begin{cases}
                    H_0 : & \mu = \mu_0; \\
                    H_1 : & \mu \neq \mu_0.
                \end{cases}
                \] Dato che lo stimatore puntuale per $\mu$ è la media campionaria $\overline{X}_n$, costruiamo 
                la regione critica del test nel modo seguente: \[
                    C \coloneqq \big\{(X_1,\, \ldots,\, X_{n}) \,:\, |\overline{X}_n -\mu_0| > c\big\}
                ,\] per una opportuna costante $c$.

                Impostiamo il livello di significatività $\alpha$ per il test individuando il valore di $c$ 
                che rende pari ad $\alpha$ la probabilità di errore di $\mathbf{I}$ specie: \[
                    \alpha = P_{\mu_0}(|\overline{X}_n -\mu_0| > c)
                .\] Indicando con $Z\sim \mathcal{N}(0,\,1)$ una variabile aleatoria normale standard, sapendo 
                che $\mu = \mu_0 \implies \overline{X}_n \sim \mathcal{N}(\mu_0,\,\sigma^2 /n)$, scriviamo 
                la seguente statistica test: \[
                    \frac{\overline{X}_n -\mu_0}{\sigma /\sqrt{n}} \overset{\mu_0}{\sim} Z
                ;\] usandola possiamo riscrivere la precedente equazione come:
                \begin{align*}
                    \alpha &= P_{\mu_0}\left(\left|\frac{\overline{X}_n -\mu_0}{\sigma /\sqrt{n}}\right| 
                    > \frac{\sqrt{n}}{\sigma}\cdot c\right)
                    = P\left(|Z| > \frac{\sqrt{n}}{\sigma}\cdot c\right) \\
                    &= 2\,P\left(Z > \frac{\sqrt{n}}{\sigma}\cdot c\right)
                .\end{align*}
                Dall'ultima relazione appena trovata segue che: \[
                    \frac{\alpha}{2} = P\left(Z > \frac{\sqrt{n}}{\sigma}\cdot c\right)
                    \iff c \cdot\frac{\sqrt{n}}{\sigma} = z_{\alpha /2} \implies 
                    c = z_{\alpha /2}\cdot \frac{\sigma}{\sqrt{n}}
                .\] Sostituendo $c$ nella regione critica $C$ definita per questo test, otteniamo le condizioni 
                di rifiuto e accettazione: \[
                    \begin{cases}
                        \text{rifiutiamo } H_0 & 
                        \text{se $\left|\frac{\overline{X}_n -\mu_0}{\sigma /\sqrt{n}}\right| > z_{\alpha /2}$;} \\
                        \text{accettiamo } H_0 & 
                        \text{se $\left|\frac{\overline{X}_n -\mu_0}{\sigma /\sqrt{n}}\right| \leq z_{\alpha /2}$.}
                    \end{cases}
                \]
            \end{defn}
            \begin{defn}[Unilaterale]
                Sia $X_1,\, \ldots,\, X_{n}$ un campione aleatorio da una popolazione normale con media $\mu$ 
                incognita e varianza $\sigma^2$ nota; fissata una costante $\mu_0$, vogliamo verificare 
                l’ipotesi nulla seguente contro l’alternativa: \[
                \begin{cases}
                    H_0 : & \mu = \mu_0; \\
                    H_1 : & \mu \geq \mu_0.
                \end{cases}
                \] Dato che lo stimatore puntuale per $\mu$ è la media campionaria $\overline{X}_n$, costruiamo 
                la regione critica del test nel modo seguente: \[
                    C \coloneqq \big\{(X_1,\, \ldots,\, X_{n}) \,:\, \overline{X}_n -\mu_0 > c\big\}
                ,\] per una opportuna costante $c$, tale che il test abbia significatività $\alpha$:
                \begin{align*}
                    \alpha &= P_{\mu_0}\left(\frac{\overline{X}_n -\mu_0}{\sigma /\sqrt{n}} 
                    > \frac{\sqrt{n}}{\sigma}\cdot c\right)
                    = P\left(Z > \frac{\sqrt{n}}{\sigma}\cdot c\right) \\
                    &= 2\,P\left(Z > \frac{\sqrt{n}}{\sigma}\cdot c\right)
                .\end{align*}
                Come nella definizione dello \emph{Z}\nbdash test bilatero, otteniamo tale valore di $c$: \[
                    c = z_{\alpha /2} \cdot\sigma /\sqrt{n}
                .\] Osserviamo che le condizioni di accettazione e rifiuto sono analoghe a quelle del test 
                bilatero, senza valore assoluto.
            \end{defn}
            \begin{obsv}
                Nel caso di test unilaterale con ipotesi: \[
                    \begin{cases}
                        H_0 : & \mu = \mu_0; \\
                        H_1 : & \mu < \mu_0.
                    \end{cases}
                ,\] le condizioni di accettazione e rifiuto risultano analoghe a quelle del test bilatero, senza 
                valore assoluto e con le disuguaglianze invertite.
            \end{obsv}
        \subsection{\emph{t}\nbdash test}\label{sec:t_test}
            \begin{defn}[Bilatero]
                Sia $X_1,\, \ldots,\, X_{n}$ un campione estratto da una popolazione con densità 
                $\mathcal{N}(\mu,\,\sigma^2)$, di cui media e varianza incognite; fissata una costante 
                $\mu_0$, vogliamo verificare l'ipotesi nulla seguente contro l'alternativa: \[
                    \begin{cases}
                        H_0 : & \mu = \mu_0; \\
                        H_1 : & \mu \neq \mu_0.
                    \end{cases}
                .\] Al contrario dello \emph{Z}\nbdash test, in questo caso non conosciamo la varianza della 
                distribuzione, dunque adottiamo come suo stimatore la varianza campionaria $S_n^2$ e 
                rifiutiamo l'ipotesi nulla quando abbiamo: \[
                \left|\frac{\overline{X}_n -\mu}{S_n /\sqrt{n}}\right| =\; \text{troppo grande}
            ,\] con $S_n$ la deviazione standard campionaria (vedere la 
            Definizione~\ref{defn:Varianza_campionaria}); definiamo il ``troppo grande'' rispetto al livello 
            di significatività $\alpha$.

            La Proprietà~\ref{prty:Distribuzione_congiunta_statistiche_normale} ci permette di affermare che, 
            indicata con $D_n$ la statistica test e sapendo $H_0$ è vera: \[
                D_n \coloneqq \frac{\overline{X}_n -\mu_0}{S_n /\sqrt{n}} \sim t(n-1)
            .\] Imponiamo quindi che il complementare della probabilità dell'errore di $\mathbf{I}$ specie sia 
            uguale a $1-\alpha$ (accettare $H_0$ quando $\mu = \mu_0$): \[
                P_{\mu_0}\left(-c \leq \frac{\overline{X}_n -\mu_0}{S_n /\sqrt{n}} \leq c\right) = 1-\alpha
            .\] Sapendo che la densità \emph{t} è simmetrica rispetto allo zero, riscriviamo la precedente 
            equazione tramite l'inverso della probabilità:
            \begin{align*}
                \alpha &= 1-P(-c \leq D_n \leq c) = P(D_n \leq -c) + P(D_n \geq c) \\
                &= 2\, P(D_n \geq c)
            .\end{align*}
            Dall'ultima relazione appena trovata segue che: \[
                c = t_{\alpha /,\, n-1}
            .\] Usando $c$ come estremo della regione critica, otteniamo le condizioni di rifiuto e 
            accettazione: \[
                \begin{cases}
                    \text{rifiutiamo } H_0 & 
                    \text{se $\left|\frac{\overline{X}_n -\mu_0}{S_n /\sqrt{n}}\right| \geq t_{\alpha /2,\, n-1}$;} \\
                    \text{accettiamo } H_0 & 
                    \text{se $\left|\frac{\overline{X}_n -\mu_0}{S_n /\sqrt{n}}\right| < t_{\alpha /2,\, n-1}$.}
                \end{cases}
            \]
            \end{defn}
            \begin{defn}[Unilaterale]
                Sia $X_1,\, \ldots,\, X_{n}$ un campione estratto da una popolazione con densità 
                $\mathcal{N}(\mu,\,\sigma^2)$ di cui media e varianza incognite; fissata una costante $\mu_0$, 
                vogliamo verificare l'ipotesi nulla seguente contro l'alternativa: \[
                    \begin{cases}
                        H_0 : & \mu = \mu_0; \\
                        H_1 : & \mu \geq \mu_0.
                    \end{cases}
                .\] Con un test di livello di significatività $\alpha$, le condizioni di accettazione e 
                rifiuto sono analoghe a quelle del test bilatero, senza valore assoluto.
            \end{defn}
            \begin{obsv}
                Nel caso di test unilaterale con ipotesi: \[
                    \begin{cases}
                        H_0 : & \mu = \mu_0; \\
                        H_1 : & \mu < \mu_0.
                    \end{cases}
                ,\] le condizioni di accettazione e rifiuto risultano analoghe a quelle del test bilatero, senza 
                valore assoluto e con le disuguaglianze invertite.
            \end{obsv}
    \section{Test per varianza di popolazione normale}
    \begin{defn}
        Sia $X_1,\, \ldots,\, X_{n}$ un campione estratto da una popolazione con densità normale di media e 
        varianza incognite; fissata una costante $\sigma^2_0$, vogliamo verificare l'ipotesi nulla seguente 
        contro l'alternativa: \[
            \begin{cases}
                H_0 : & \mu = \mu_0; \\
                H_1 : & \mu \neq \mu_0.
            \end{cases}
        \] Quando $H_0$ è vera, possiamo usare il Teorema~\ref{thm:Distribuzione_congiunta_statistiche_normale} 
        per ottenere la statistica test seguente: \[
            D_n \coloneqq \frac{S_n^2}{\sigma_0^2}(n-1) \sim  \chi^2(n-1)
        ;\] Impostiamo il test a livello di significatività $\alpha$ tramite la probabilità:
        \begin{align*}
            1-\alpha = P_{(\mu,\,\sigma^2)}\left(\chi^2_{1-\alpha /2,\,n-1} < \frac{S_n^2}{\sigma_0^2}\cdot(n-1) 
            < \chi^2_{\alpha /2,\,n-1}\right)
        .\end{align*}
        Le condizioni di rifiuto e accettazione per un test di livello di significatività $\alpha$ con la 
        statistica test $D_n$ sono ottenute come: \[
            \begin{cases}
                \text{rifiutiamo } H_0 & 
                \text{se $\frac{S_n^2}{\sigma_0^2}(n-1) \leq \chi^2_{1-\alpha /2,\,n-1} \lor 
                \frac{S_n^2}{\sigma_0^2}(n-1) \geq \chi^2_{\alpha /2,\,n-1}$;} \\
                \text{accettiamo } H_0 & 
                \text{se $\chi^2_{1-\alpha/2,\,n-1} < \frac{S_n^2}{\sigma_0^2}(n-1) < \chi^2_{\alpha/2,\,n-1}$.}
            \end{cases}
        .\] 
    \end{defn}
    \section{Confronto media tra popolazioni normali indipendenti}
        \begin{defn}[$\mu_x=\mu_y=\,?,\, \sigma^2_x=\sigma^2_{x,\,0},\, \sigma^2_y=\sigma^2_{y,\,0}$]
            \hfill \\
            Consideriamo i campioni $X_1,\, \ldots,\, X_{n}$ e $Y_1,\, \ldots,\, Y_{m}$, estratti da due 
            popolazioni normali indipendenti con medie $\mu_x,\, \mu_y$ incognite e varianze 
            $\sigma_x,\, \sigma_y$ note; impostiamo quindi il test d'ipotesi seguente: \[
            \begin{cases}
                H_0 : & \mu_x = \mu_y; \\
                H_1 : & \mu_x \neq \mu_y.
            \end{cases} \implies
            \begin{cases}
                H_0 : \mu_x -\mu_y = 0; \\
                H_1 : \mu_x -\mu_y \neq 0.
            \end{cases}
            \] Dato che $\overline{X}_n$ è uno stimatore non distorto di $\mu_x$ e $\overline{Y}_m$ è uno 
            stimatore non distorto di $\mu_y$, possiamo usare $\overline{X}_n -\overline{Y}_m$ come stimatore 
            di $\mu_x -\mu_y$, nella riscrittura delle ipotesi.

            La regione critica del test avrà la forma seguente: \[
                C \coloneqq \big\{\vec{X}_n,\, \vec{Y}_m \,:\, |\overline{X}_n - \overline{Y}_m| > c\big\}
            ,\] per una opportuna costante $c$; ricordiamo che vale: \[
                \overline{X}_n -\overline{Y}_m \sim \mathcal{N}\left(\mu_x -\mu_y,\, \frac{\sigma_x^2}{n} 
                +\frac{\sigma_y^2}{m}\right)
            .\] Allora quando $H_0$ è vera la statistica test diventa: \[
                D_{n,\,m} \coloneqq \frac{\overline{X}_n -\overline{Y}_m -(\cancel{\mu_x -\mu_y})}
                {\sqrt{\frac{\sigma_x^2}{n} +\frac{\sigma_y^2}{m}}} \sim \mathcal{N}(0,\,1)
            .\] Otteniamo la significatività $\alpha$ con la seguente probabilità di accettare $H_0$: \[
            1-\alpha = P_{(\mu_x,\,\mu_y)}\left(-z_{\alpha /2} \leq \frac{\overline{X}_n 
            -\overline{Y}_m}{\sqrt{\frac{\sigma^2_y}{n} +\frac{\sigma^2_y}{m}}} \leq z_{\alpha /2}\right)
            .\] Deduciamo che le condizioni di accettazione e rifiuto per il test di significatività $\alpha$ 
            con la statistica $D_{n,\,m}$ saranno: \[
            \begin{cases}
                \text{rifiutiamo } H_0 & 
                \text{se $\frac{|\overline{X}_n -\overline{Y}_m|}{\sqrt{\frac{\sigma_x^2}{n}} 
                +\frac{\sigma_y^2}{m}} > z_{\alpha /2}$;} \\
                \vspace{-1em} \\
                \text{accettiamo } H_0 & 
                \text{se $\frac{|\overline{X}_n -\overline{Y}_m|}{\sqrt{\frac{\sigma_x^2}{n}} 
                +\frac{\sigma_y^2}{m}} \leq z_{\alpha /2}$.}
            \end{cases}
            \]
        \end{defn}
    \begin{defn}[$\mu_x=\mu_y=\,?,\, \sigma^2_x=\sigma^2_y=\,?,\, \sigma^2_x \equiv \sigma^2_y$]
            \hfill \\
            Consideriamo i campioni $X_1,\, \ldots,\, X_{n}$ e $Y_1,\, \ldots,\, Y_{m}$, estratti da due 
            popolazioni normali indipendenti con medie $\mu_x,\, \mu_y$ incognite e varianze 
            $\sigma_x,\, \sigma_y$ incognite ma supposte uguali; impostiamo quindi il test d'ipotesi seguente: \[
            \begin{cases}
                H_0 : & \mu_x = \mu_y; \\
                H_1 : & \mu_x \neq \mu_y.
            \end{cases}
            \] Come il test precedente, vogliamo rifiutare $H_0$ quando $\overline{X}_n -\overline{Y}_m$ è 
            lontano da $0$; per ottenere i limiti della regione critica, cerchiamo la distribuzione della 
            statistica test quando $H_0$ è vera.

            Per fare ciò prima di tutto definiamo lo \emph{stimatore pooled} di $\sigma^2$, dove 
            $\sigma^2 = \sigma^2_x = \sigma^2_y$ per indicare entrambe le varianze, supposte uguali:
            \begin{equation}\label{eq:Stimatore_pooled_varianza}
                S^2_p \coloneqq \frac{(n-1)S_x^2 +(m-1)S_y^2}{n+m-2} \sim \chi^2(n+m-2)
            .\end{equation}
            Per $H_0$ vera la statistica test sarà costruita come: \[
                D_{n,\,m} \coloneqq \frac{\overline{X}_n -\overline{Y}_m}{S_p\cdot \sqrt{\frac{1}{n} +\frac{1}{m}}} 
                \sim t(n+m-2)
            .\] Otteniamo la significatività $\alpha$ con la seguente probabilità di rifiutare $H_0$: \[
                \alpha = P_{(\mu_x,\,\mu_y)}\left(\left|\frac{\overline{X}_n -\overline{Y}_m}{S_p 
                \cdot \sqrt{\frac{1}{n} +\frac{1}{m}}}\right| \geq t_{\alpha /2,\,n+m-2}\right)
            .\] Deduciamo che le condizioni di accettazione e rifiuto per il test di significatività $\alpha$ 
            con la statistica $D_{n,\,m}$ saranno: \[
            \begin{cases}
                \text{rifiutiamo } H_0 & 
                \text{se $\left|\frac{\overline{X}_n -\overline{Y}_m}{\sqrt{\frac{1}{n}} 
                +\frac{1}{m}}\right| > t_{\alpha /2,\,n+m-2}$;} \\
                \vspace{-1em} \\
                \text{accettiamo } H_0 & 
                \text{se $\left|\frac{\overline{X}_n -\overline{Y}_m}{\sqrt{\frac{1}{n}} 
                +\frac{1}{m}}\right| \leq t_{\alpha /2,\,n+m-2}$.}
            \end{cases}
            \]
        \end{defn}
        \begin{defn}[$\mu_x=\mu_y=\,?,\, \sigma^2_x=\sigma^2_y=\,?,\, \sigma^2_x \equiv \sigma^2_y$]
            \hfill \\
            Consideriamo i campioni $X_1,\, \ldots,\, X_{n}$ e $Y_1,\, \ldots,\, Y_{m}$, estratti da due 
            popolazioni normali indipendenti con medie $\mu_x,\, \mu_y$ incognite e varianze 
            $\sigma_x,\, \sigma_y$ incognite (non possiamo nemmeno assumerle uguali); impostiamo quindi il 
            test d'ipotesi seguente: \[
                \begin{cases}
                    H_0 : & \mu_x = \mu_y; \\
                    H_1 : & \mu_x \neq \mu_y.
                \end{cases}
            \] La statistica test che useremo, assumendo verificata $H_0$, è la seguente:
            \begin{align*}
                D_{n,\,m} \coloneqq \frac{\overline{X}_n -\overline{Y}_m}{\sqrt{\frac{S_n^2}{n} 
                +\frac{S_m^2}{m}}} \sim \mathcal{N}(0,\,1) & &
                \text{per } n,\,m \gg 1
            .\end{align*}
            Per $n$ e $m$ molto grandi, infatti, la sua distribuzione può essere approssimata con 
            quella normale standard, semplificando la complessità data dalla dipendenza dalle varianze 
            campionarie incognite.

            Le condizioni di accettazione e rifiuto per un test di significatività 
            \underline{approssimativamente} $\alpha$ con statistica test $D_{n,\,m}$ sono: \[
            \begin{cases}
                \text{rifiutiamo } H_0 & 
                \text{se $\frac{|\overline{X}_n -\overline{Y}_m|}{\sqrt{\frac{S_x^2}{n}} 
                +\frac{S^2}{m}} > z_{\alpha /2}$;} \\
                \vspace{-1em} \\
                \text{accettiamo } H_0 & 
                \text{se $\frac{|\overline{X}_n -\overline{Y}_m|}{\sqrt{\frac{S_x^2}{n}} 
                +\frac{S_y^2}{m}} \leq z_{\alpha /2}$.}
            \end{cases}
            \]
        \end{defn}
    \section{Confronto varianza tra popolazioni normali indipendenti}
        \begin{defn}[$\mu_x =\mu_y =\,?,\, \sigma^2_x =\sigma^2_y =\,?$]
            \hfill \\
            Siano $X_1,\, \ldots,\, X_{n}$ e $Y_1,\, \ldots,\, Y_{m}$ due campioni estratti da 
            popolazioni indipendenti con distribuzioni normali, di parametri incogniti 
            $\mu_x,\,\sigma^2_x$ e $\mu_y,\,\sigma^2_y$; impostiamo il test d'ipotesi seguente: \[
                \begin{cases}
                    H_0 : & \sigma^2_x = \sigma^2_y; \\
                    H_1 : & \sigma^2_x \neq \sigma^2_y.
                \end{cases}
            \] Usando la varianza campionaria come stimatore, dal 
            Teorema~\ref{thm:Distribuzione_congiunta_statistiche_normale} sappiamo che:
            \begin{align*}
                (n-1)\cdot \frac{S_x^2}{\sigma_x^2} \sim \chi^2(n-1) & &
                (m-1)\cdot \frac{S_y^2}{\sigma_y^2} \sim \chi^2(m-1)
            ;\end{align*}
            quando si verifica l'ipotesi $H_0$ la statistica test è la seguente: \[
                D_{n,\,m} \coloneqq \frac{S_x^2}{S_y^2} \cdot \frac{\cancel{\sigma_y^2}}{\cancel{\sigma_x^2}} 
                \sim \mathcal{F}(n-1,\,m-1)
            .\] Otteniamo la significatività $\alpha$ con la seguente probabilità di accettare $H_0$: \[
            1-\alpha = P_{(\sigma_x^2,\,\sigma_y^2)}\left(\mathcal{F}_{1-\alpha /2,\,n-1,\,m-1} \leq 
            \frac{S_x^2}{S_y^2} \leq \mathcal{F}_{\alpha /2,\,n-1,\,m-1}\right)
            .\] Le condizioni di accettazione e rifiuto per un test di significatività $\alpha$ con 
            statistica test $D_{n,\,m}$ sono: \[
            \begin{cases}
                \text{rifiutiamo } H_0 & 
                \text{se $S_x^2 /S_y^2 \leq \mathcal{F}_{1-\alpha /2,\,n-1,\,m-1} \lor
                S_x^2 /S_y^2 \geq \mathcal{F}_{\alpha /2,\,n-1,\,m-1}$;} \\
                \text{accettiamo } H_0 & 
                \text{se $\mathcal{F}_{1-\alpha /2,\,n-1,\,m-1} \leq S_x^2 /S_y^2
                \leq \mathcal{F}_{\alpha /2,\,n-1,\,m-1}$.}
            \end{cases}
            \] 
        \end{defn}
    \section{Test per campioni di coppie di dati normali}
        \begin{defn}
            Consideriamo il caso di un campione costituito da $n$ coppie \\
            $(X_1,\,Y_1),\, \ldots,\, (X_n,\,Y_n)$ nel quale ciascuna coppia $(X_i,\,Y_i)$ è indipendente, 
            ma le componenti $X_i,\,Y_i$ non lo sono.

            Consideriamo il campione aleatorio $\vec{W} \coloneqq W_1 = Y_1-X_1,\, \ldots,\, W_n=Y_n-X_n$ e 
            sapendo che il valore atteso di $W$ (che indicheremo con $\mu_w$) è nullo quando si verifica 
            un evento $H_0$, possiamo costruire un test come: \[
                \begin{cases}
                    H_0 : & \mu_w = 0; \\
                    H_1 : & \mu_w \neq 0.
                \end{cases}
            \] Possiamo usare un \emph{t}\nbdash test poiché testiamo la media di una popolazione normale con 
            media e varianza incognite (Sezione~\ref{sec:t_test}); ricaviamo le seguenti regole di rifiuto e 
            accettazione con significatività $\alpha$: \[
                \begin{cases}
                    \text{rifiutiamo } H_0 & 
                    \text{se $\frac{\overline{W}_n}{S_w^2 /\sqrt{n}} \leq -t_{\alpha,\, n-1}$;} \\
                    \text{accettiamo } H_0 & 
                    \text{se $\frac{\overline{W}_n}{S_w^2 /\sqrt{n}} > -t_{\alpha,\, n-1}$.}
                \end{cases}
            .\] 
        \end{defn}
    \section{Confronto parametri tra popolazioni Bernoulliane indipendenti}
        \begin{defn}[Proporzione]
            Consideriamo due campioni indipendenti $X_1,\, \ldots,\, X_{n_1}$ e $Y_1,\, \ldots,\, Y_{n_2}$ 
            estratti da due popolazioni Bernoulliane con probabilità di successo rispettivamente $p_1$ e $p_2$; 
            se contiamo i successi nel primo e nel secondo campione rispettivamente con $s_{n_1}$ e $S_{n_2}$, 
            allora abbiamo:
            \begin{align*}
                S_{n_1} \sim \mathcal{B}i(n_1,\,p_1) & &
                S_{n_2} \sim \mathcal{B}i(n_2,\,p_2)
            ;\end{align*}
            sappiamo che le precedenti variabili aleatorie sono indipendenti, e se $n_1$ e $n_2$ sono 
            ``grandi'', per il Teorema~\ref{thm:Teorema_DeMoivre_Laplace} possiamo scriverle come:
            \begin{align*}
                \frac{S_{n_1}}{n_1} \sim \mathcal{N}\left(p_1,\, \frac{p_1\cdot(1-p_1)}{n_1}\right) & &
                \frac{S_{n_2}}{n_2} \sim \mathcal{N}\left(p_2,\, \frac{p_2\cdot(1-p_2)}{n_2}\right)
            ,\end{align*}
            da cui segue che la distribuzione della differenza si ottiene come:
            \begin{align*}
                \frac{S_{n_1}}{n_1} - \frac{S_{n_2}}{n_2} \sim \mathcal{N}\left(p_1-p_2,\, 
                \frac{p_1\cdot(1-p_1)}{n_1} + \frac{p_2\cdot(1-p_2)}{n_2}\right)
            .\end{align*}
            Siano i due parametri $p_1$ e $p_2$ sono incogniti e impostiamo il test d'ipotesi seguente: \[
                \begin{cases}
                    H_0 : & p_1 = p_2; \\
                    H_1 : & p_1 \neq p_2.
                \end{cases}
            .\] Se consideriamo verificata $H_0$, possiamo scrivere:
            \begin{align*}
                \frac{(S_{n_1} /n_1) - (S_{n_2} /n_2)}{\sqrt{p\cdot(1-p)(1 /n_1 + 1 /n_2)}} \sim 
                \mathcal{N}(0,\,1)
                & & \text{per } p = p_1 = p_2
            ;\end{align*}
            notiamo tuttavia che per la presenza del parametro incognito $p$, non possiamo considerare la 
            precedente scrittura una statistica test.

            Stimiamo allora il parametro incognito tramite i campioni delle due popolazioni; considerando 
            verificata l'ipotesi $H_0$ abbiamo: \[
                p_1 = p_2 \implies S_{n_1} + S_{n_2} \sim \mathcal{B}i(n_1+n_2,\, p)
            .\] Per il Teorema~\ref{thm:Legge_grandi_numeri_forte}, quando $n_1$ e $n_2$ sono grandi vale: \[
                \frac{S_{n_1} + S_{n_2}}{n_1 + n_2} \sim p
            ;\] concludiamo che una scelta valida per la statistica test è la seguente: \[
                \tilde{Z_0} \coloneqq \frac{S_{n_1} - S_{n_2}}{\sqrt{\frac{S_{n_1}+S_{n_2}}{n_1+n_2}\cdot
                \left(1- \frac{S_{n_1}+S_{n_2}}{n_1+n_2}\right)\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}}
                \sim \mathcal{N}(0,\,1)
            .\] Per costruire un test di livello di significatività $\alpha$ usiamo il quantile della normale 
            standard di ordine $\alpha/2$, ottenendo le seguenti condizioni di rifiuto e accettazione: \[
                \begin{cases}
                    \text{rifiutiamo } H_0 & 
                    \text{se $|\tilde{Z_0}| \geq z_{\alpha /2}$;} \\
                    \text{accettiamo } H_0 & 
                    \text{se $|\tilde{Z_0}| < z_{\alpha /2}$.}
                \end{cases}
            \] 
        \end{defn}
    \section{Test uguaglianza distribuzioni tra popolazioni normali}
        %TODO: Completare sezione
    \section{Test $\chi^2$ di buon adattamento}\label{sec:Chi2_buon_adattamento}
        \begin{defn}[buon adattamento]
            I test statistici che servono per verificare se un dato modello probabilistico sia 
            compatibile con i dati, sono detti test \emph{sulla bontà di adattamento} (o di 
            buon adattamento).
        \end{defn}
        \begin{defn}
            Consideriamo una popolazione formata da oggetti classificabili in $k$ categorie 
            diverse; per $i \in [1,\,k]$ sia $p_i$ la probabilità che un oggetto scelto a caso 
            dalla popolazione, appartenga alla classe $i$\nbdash esima; deve valere:
            \begin{align*}
                p_i \geq 0, & &
                \sum_{i=1}^{k} p_i = 1
            .\end{align*}
            Siano inoltre $p^0_1,\, \ldots,\, p^0_{k}$ $k$ numeri assegnati, che soddisfino le 
            proprietà appena enunciate per i $p_i$; impostiamo il test di buon adattamento come: \[
                \begin{cases}
                    H_0 : & \forall i \in [1,\,k] \,:\, p_i = p_i^0; \\
                    H_1 : & \exists i \in [1,\,k] \,:\, p_i \neq p_i^0.
                \end{cases}
            \] Se consideriamo un campione $X_1,\, \ldots,\, X_{n}$ estratto dalla popolazione, il 
            quale contiene $n$ osservazioni indipendenti e ciascuna ha probabilità $p_i$ di 
            appartenere alla classe $i$\nbdash esima, allora indichiamo con  $X_i = n^0$ le 
            osservazioni comprese nel campione che fanno parte della classe $i$\nbdash esima.

            Possiamo osservare la seguente distribuzione per la frequenza assoluta della 
            classe $i$\nbdash esima nel campione:
            \begin{align*}
                X_i \sim \mathcal{B}i(n,\,p_i) \implies \text{E}(X_i)= n\cdot p_i & &
                \text{per } i \in [1,\,k]
            .\end{align*}
            Prendiamo come statistica test:
            \begin{align*}
                D_n \coloneqq \sum_{i=1}^{k} \frac{(X_i -np_i^0)^2}{np_i^0}
            ,\end{align*}
            dato che la quantità $(X_i -np_i^0)^2$ ci indica quanto è verosimile accettare 
            l'ipotesi nulla $H_0$.

            Inoltre, rifiutiamo l'ipotesi nulla quando $D_n > c$, dove la costante $c$ dipende 
            dal livello di significatività del test:
            \begin{align*}
                \alpha &= P_i\left(D_n \geq c\right)
            .\end{align*}
            Possiamo concludere, per $n$ ``grande'' e $H_0$ verificata, che: \[
                D_n \sim \chi^2(k-1) \implies c \simeq \chi^2_{\alpha,\, k-1}
            .\] In conclusione, data statistica test $D_n$ definita sopra e la realizzazione 
            $\bar{d}$ corrispondente al campione $\vec{X}$, le condizioni di accettazione e 
            rifiuto per un test di \emph{livello approssimato} $\alpha$ sono: \[
                \begin{cases}
                    \text{rifiutiamo } H_0 & 
                    \text{se $\bar{d} \geq \chi^2_{\alpha,\, k-1}$;} \\
                    \text{accettiamo } H_0 & 
                    \text{se $\bar{d} < \chi^2_{\alpha,\, k-1}$.}
                \end{cases}
            .\] 
        \end{defn}
        \begin{prty}
            \hfill
            \begin{enumerate}
                \item Il numero di elementi $n$ che costituiscono il campione di un test $\chi^2$ 
                    di buon adattamento è abbastanza ``grande'' quando:
                    \begin{itemize} \label{itm:n_grande_Chi_quadro_adattamento}
                        \item almeno $4 /5$ degli $np_i^0 \geq 5$;
                        \item le rimanenti $np_i^0 > 1$.
                    \end{itemize}
                \item possiamo dimostrare la relazione: \[
                    D_n = \sum_{i=1}^{k} \frac{(X_i -np_i^0)^2}{np_i^0} = 
                    \sum_{i=1}^{k} \frac{X_i^2}{np_i^0}-n
                ;\] 
                \item se abbiamo $k=2$ classi allora $X_1+X_2=n$ e $p_1^0+p_2^0=1$, e inoltre: \[
                    D_n \sim \chi^2(1)
                ;\] 
                \item se abbiamo $k > 2$ classi allora: \[
                    D_n \sim \chi^2(k-1)
                .\] 
            \end{enumerate}
        \end{prty}
        \begin{proof}
            \hfill
            \begin{enumerate}
                \setcounter{enumi}{1}
                \item Riscriviamo la forma dello stimatore come segue:
                    \begin{align*}
                        D_{n} &= \sum_{i=1}^{k} \frac{(X_i - np_i^0)^2}{np^0_i} =
                            \sum_{i=1}^{k} \frac{X_i^2 +n^2(p_i^0)^2 -2np_i^0 X_i}{np_i^0} \\
                        &= \sum_{i=1}^{k} \frac{X_i^2}{np_i^0} + n\cdot \sum_{i=1}^{k} p_i^0 - 
                              2\cdot \sum_{i=1}^{k} X_i \\
                        &= \sum_{i=1}^{k} \frac{X_i^2}{np_i^0} - n & \text{per }
                            \sum_{i=1}^{k} p_i^0 = 1 \land \sum_{i=1}^{k} X_i = n
                        .\end{align*}
                \item Scegliamo $k=2$ classi, di conseguenza $X_1+X_2 = n$ e $p_1^0 + p_2^0 = 1$; 
                    allora possiamo scrivere lo stimatore come:
                    \begin{align*}
                        D_n &= \frac{(X_1 -np_1^0)^2}{np_1^0} + \frac{(X_2 -np_2^0)^2}{np_2^0} \\
                            &= \frac{(X_1 -np_1^0)^2}{np_1^0} + \frac{(n-X_1-n(1-p_1^0))^2}{n(1-p_1^0)} \\
                            &= \frac{(X_1 -np_1^0)^2}{np_1^0} + \frac{(X_1-np_0)^2}{n(1-p_1^0)} \\
                            &= \frac{(X_1 -np_1^0)^2}{np_1^0(1-p_1^0)}
                    .\end{align*}
                    Se vale l'ipotesi di un $n$ ``grande'' allora si verifica che:
                    \begin{equation*}
                        \frac{X_1-np_1^0}{\sqrt{np_1^0(1-p_1^0)}} \sim \mathcal{N}(0,\,1) \implies 
                        D_n = \frac{(X_1 -np_1^0)^2}{np_1^0(1-p_1^0)} \sim \chi^2(1)
                    .\end{equation*}
                \item Poniamoci nel caso di $n$ ``grande'', sappiamo quindi che la statistica test $D_n$ è 
                    funzione delle variabili $X_1,\, \ldots,\, X_{k}$ tali che $\sum_{i=1}^{k} X_i = n$; 
                    possiamo affermare che il legame tra le variabili $X_i$ fa ``perdere un grado di libertà'' 
                    sotto l'ipotesi $\mathbb{H}_0$. \qedhere
            \end{enumerate}
        \end{proof}
        \subsection{Dati con densità discreta a meno di parametri}
            \begin{defn}
                Nel caso in cui le probabilità $\{p_i = 1,\, \ldots,\, k\}$ non siano completamente specificate, 
                costruiamo le ipotesi del test chiedendoci se la distribuzione in esame sia una Poisson di parametro 
                $\lambda$ non specificato: \[
                    \begin{cases}
                        H_0 : & \exists \lambda \,:\, F \sim \mathcal{P}(\lambda); \\
                        H_1 : & \nexists \lambda \,:\, F \sim \mathcal{P}(\lambda).
                    \end{cases}
                \]
                Procediamo quindi nel modo seguente:
                \begin{itemize}
                    \item effettuiamo una stima di $\lambda$ basandoci sui dati, indicandola con $\hat{\lambda}$;
                    \item sostituiamo $\lambda$ con $\hat{\lambda}$ nelle espressioni delle probabilità $p_i^0$, 
                        indicando con $\hat{p_i}$ il risultato ottenuto;
                    \item adoperiamo la statistica test $\tilde{D_n} \coloneqq \sum_{i=1}^{n} 
                        \frac{(X_i-\hat{n}p_i)}{\hat{n}p_i}$, dove indichiamo con $X_i$ la frequenza della classe 
                        i\nbdash esima nel campione;
                    \item si dimostra che sotto $\mathbb{H}_0$ e per $n$ ``grande'', la statistica test adottata vale: \[
                            \tilde{D_n} \sim \chi^2(k - 1 - s) = \chi^2(k-2)
                        ,\] con $k$ il numero di classi differenti e $s=1$ il numero di parametri da stimare.
                \end{itemize}
                Un test di livello $\alpha$ è quello che, in corrispondenza della realizzazione $\tilde{D_n} = \tilde{d}$ 
                possiede le seguenti condizioni di accettazione e rifiuto: \[
                \begin{cases}
                    \text{rifiutiamo } H_0 & 
                    \text{se $\tilde{d} \geq \chi^2_{\alpha,\,k-2}$;} \\
                    \text{accettiamo } H_0 & 
                    \text{se $\tilde{d} < \chi^2_{\alpha,\,k-2}$.}
                \end{cases}
                \]
                \end{defn}
        \subsection{Dati con densità continua}
            \begin{defn}
                Sia $Y_1,\, \ldots,\, Y_{n}$ un campione aleatorio estratto da una distribuzione continua $F$; sia inoltre 
                $F_0$ una distribuzione continua \underline{assegnata}. Stabiliamo sulla base del campione il seguente 
                test d'ipotesi: \[
                    \begin{cases}
                        H_0 : & F = F_0; \\
                        H_1 : & F \neq F_0.
                    \end{cases}
                .\] Possiamo affrontare il problema suddividendo l'insieme dei possibili valori della variabile aleatoria 
                $Y_j$ nell'ipotesi $\mathbb{H}_0$ in $k$ intervalli disgiunti: \[
                (y_0,\,y_1],\, \ldots,\, (y_{k-1},\,y_k]
                ;\] possiamo considerare i $k$ intervalli come le classi in cui suddivideremo l'osservazione.
                Le probabilità con cui le osservazioni assumono valori in queste classi sono definite come:
                \begin{align*}
                    p_i = P\left(Y_j \in (y_{i-1},\,y_i]\right) & & \text{per } i \in [1,\,k]
                ,\end{align*}
                e sotto l'ipotesi nulla $\mathbb{H}_0$ questa probabilità vale:
                \begin{align*}
                    p_i^0 = P_{\mathbb{H}_0}\left(Y_{j} \in (y_{i-1},\,y_i]\right) = F_0(y_i) -F_0(y_{i-1})
                    & & \text{per } i \in [1,\,k]
                .\end{align*}
                Concludiamo riformulando il problema iniziale come un test d'ipotesi del tipo: \[
                    \begin{cases}
                        H_0 : & \forall i \in [1,\,k] \,:\, p_i = p_i^0; \\
                        H_1 : & \exists i \in [1,\,k] \,:\, p_i \neq p_i^0.
                    \end{cases}
                \] Possiamo analizzare queste ipotesi con un test $\chi^2$ di buon adattamento 
                (§\ref{sec:Chi2_buon_adattamento}).
            \end{defn}
    \section{Test $\chi^2$ di indipendenza}
        \begin{defn}
            Consideriamo una popolazione nella quale ogni elemento possa essere classificato in base a due caratteristiche 
            o criteri, chiamati $X \in [1,\,r]$ e $Y \in [1,\,s]$. Selezionando a caso $n$ individui della popolazione, 
            consideriamo le corrispondenti caratteristiche $(X_i,\,Y_i)$ per $i\in [1,\,n]$: anche se in genere le 
            caratteristiche $X_i$ e $Y_i$ sono correlate, possiamo assumere i vettori $(X_i,\,Y_i)$ indipendenti.

            Verifichiamo dunque l'indipendenza delle due caratteristiche $X_i$ e $Y_i$, adottando come campione aleatorio 
            la successione di vettori $(X_1,\,Y_1),\, \ldots,\, (X_n,\,Y_n)$ e denotiamo le densità di probabilità come:
            \begin{align*}
                p_{i,\,j} \coloneqq P(X=i,\,Y=j),\, p_i\coloneqq P(X=i),\, q_j\coloneqq P(Y=j)
            ;\end{align*}
            sulla base del campione vogliamo verificare le seguenti ipotesi: \[
                \begin{cases}
                    H_0 : & \forall i \in [1,\,r] \,\forall j \in [1,\,s] \,:\, p_{i,\,j} = p_iq_j; \\
                    H_1 : & \exists i \in [1,\,r] \,\exists j \in [1,\,s] \,:\, p_{i,\,j} \neq p_iq_j.
                \end{cases}
            \] Per costruire la statistica test definiamo i seguenti elementi:
            \begin{itemize}
                \item $N_{i,\,j}$ il numero degli elementi dal campione, che sono uguali a $(i,\,j)$, ovvero la frequenza 
                    di $(i,\,j)$ nel campione;
                \item $N_i \coloneqq \sum_{j=1}^{s} N_{i,\,j}$ il numero delle $X_1,\, \ldots,\, X_{n}$ che sono 
                    uguali a $i$, ovvero la frequenza di $i$ tra le variabili aleatorie $X_1,\, \ldots,\, X_{n}$;
                \item $M_j \coloneqq \sum_{i=1}^{r} N_{i,\,j}$ il numero delle $Y_1,\, \ldots,\, Y_{n}$ che sono 
                    uguali a $j$, ovvero la frequenza di $j$ tra le variabili aleatorie $Y_1,\, \ldots,\, Y_{n}$;
                \item $\hat{p}_i \coloneqq N_i \slash n$, $\hat{q}_j \coloneqq M_j \slash n$.
            \end{itemize}
            Se utilizziamo la segiente statistica test: \[
                D_n^* \coloneqq \sum_{j=1}^{s} \sum_{i=1}^{r} \frac{(N_{i,\,j} - n \hat{p}_i\hat{q}_j)^2}{n\hat{p}_i\hat{q}_j}
            ,\] possiamo dimostrare che con $n$ ``grande'' e sotto l'ipotesi $\mathbb{H}^0$ vale: \[
            D_n^* \sim \chi^2\left((r-1) \times (s-1)\right) \implies P_{\mathbb{H}^0}\left(D_n^* 
                \geq \chi^2_{\alpha,\, (r-1) \times (s-1)}\right) \simeq \alpha
            .\] 
        \end{defn}
        \begin{proof}
            Consideriamo ciascuna coppia $(i,\,j)$, a cui corrisponde $N_{i,\,j}$ che rappresenta il numero di 
            elementi del campione uguali a $(i,\,j)$; possiamo rappresentare la distribuzione di questa variabile 
            aleatoria come una binomiale: \[
                N_{i,\,j} \sim \mathcal{B}i(n,\,p_{i,\,j})
            ,\] dove abbiamo usato il parametro $p_{i,\,j} = P(X=i,\,Y=j)$ definito in precedenza.

            Possiamo calcolare il valore atteso della frequenza di $(i,\,j)$ come: \[
                \text{E}(N_{i,\,j}) = n\cdot p_{i,\,j} \underset{\mathbb{H}_0}{=} n \cdot p_i q_j = nP(X=i)P(Y=j)
            .\] Deduciamo che per un valore grande di $(N_{i,\,j} - np_iq_j)^2$ rifiuteremo l'ipotesi nulla di 
            indipendenza; poiché $p_i$ e $q_j$ sono incognite, calcoliamo una loro stima tramite 
            $\hat{p}_i$ e $\hat{q}_j$.

            Considerata la statistica test $D_n^*$, le condizioni di accettazione e rifiuto del test sono determinate 
            come: \[
                \begin{cases}
                    \text{rifiutiamo } H_0 & 
                    \text{se $d^* \geq \chi^2_{\alpha,\,(r-1)\times (s-1)}$;} \\
                    \text{accettiamo } H_0 & 
                    \text{se $d^* < \chi^2_{\alpha,\,(r-1)\times (s-1)}$.}
                \end{cases}
            \] Possiamo determinare il p\nbdash value di questo test come \[
            P_{\mathbb{H}_0}(D_n^* \geq d^*) \sim P(\chi^2((r-1)\times (s-1)))
            .\qedhere\] 
        \end{proof}
