%! TEX root = main.tex
% Capitolo 2

\chapter{Variabili Aleatorie}
    \section{Variabile aleatoria o casuale}
        \begin{defn}\label{defn:Variabile_aleatoria}
            Consideriamo lo spazio di probabilità $(\Omega,\,\mathscr{F},\,P)$; una \textit{variabile aleatoria} $X$ è una funzione da $\Omega$ in $\mathbb{R}$ tale che: \[
                \forall x \in \mathbb{R} \,:\, \{X \leq x\} \coloneqq \{\omega \in \Omega \,:\, X(\omega) \leq x\} \in \mathscr{F}
            .\]
        \end{defn}
        \begin{prty}\label{prty:Variabile_aleatoria}
            Se $X$ è una variabile aleatoria allora i seguenti insiemi sono eventi, ovvero sottoinsiemi di $\Omega$ che appartengono a $\mathscr{F}$:
            \begin{align*}
                &\{X < x\}, & &\{X \geq x\}, & &\{X > x\}, \\
                &\{x < X < y\}, & &\{x \leq X < y\}, & &\{x < X \leq y\}, \\
                &\{x \leq X \leq y\}, & &\{X = x\}, & &\{X \neq x\}
            .\end{align*}
        \end{prty}
    \section{Funzione di ripartizione}
        \begin{defn}\label{defn:Funzione_ripartizione}
            Sia $X$ una variabile aleatoria definita su uno spazio di probabilità $(\Omega,\,\mathscr{F},\,P)$; chiamiamo \textit{funzione di ripartizione} di $X$ la funzione $F_X\,:\, \mathbb{R} \mapsto [0,\,1]$ definita come: \[
                \forall x \in \mathbb{R} \,:\, F_X(x) \coloneqq P(X \leq x)
            .\]
        \end{defn}
        \begin{obsv}\label{obsv:Funzione_ripartizione}
            Sia $X$ una variabile aleatoria definita sullo spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ e sia dato $x \in \mathbb{R}$ che definisce la funzione di ripartizione $F_X(x) \coloneqq P(X \leq x)$; per il punto $(2)$ della Proprietà~\ref{prty:Spazio_di_probabilità} possiamo scrivere:
            \begin{enumerate}[\indent (a)]
                \item Consideriamo la probabilità inversa della funzione di ripartizione:
                    \begin{align*}
                        P(X > x) &= P(\{\omega \in \Omega \,:\, X(\omega) > x\}) = P(\{\omega \in \Omega \,:\, X(\omega) \leq x\}^{\text{C}}) \\
                                 &= 1 - P(\{\omega \in \Omega \,:\, X(\omega) \leq x\}) \\
                                 &= 1 - P(X \leq x)
                    .\end{align*}
                \item Se invece abbiamo $x,\,y \in \mathbb{R}$ con $x < y$, per il punto $(3)$ della Proprietà~\ref{prty:Proprietà_funzione_probabilità} vale:
                    \begin{align*}
                        P(x < X \leq y) &= P(\{\omega \in \Omega \,:\, x < X(\omega) \leq y\}) \\
                                     &= P(\{\omega \in \Omega \,:\, X(\omega) \leq y\} \backslash \{\omega \in \Omega \,:\, X(\omega) \leq x\}) \\
                                     &= P(\{\omega \in \Omega \,:\, X(\omega) \leq y\} - \{\omega \in \Omega \,:\, X(\omega) \leq x\}) \\
                                     &= P(X \leq y) - P(X \leq x)
                    .\end{align*}
            \end{enumerate}
            Osserviamo che la conoscenza della funzione di ripartizione di $X$ ci permette di calcolare le probabilità di eventi ad essa associati.
            \begin{prty}\label{prty:Funzione_ripartizione}
                Sia $X$ una variabile aleatoria definita sullo spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ e la sua funzione di ripartizione $F_X(x) = P(X \leq x)$; allora possiamo affermare che:
                \begin{itemize}
                    \item $F_X(x)$ è una funzione \textit{monotona non decrescente};
                    \item $F_X(x)$ è \textit{continua} da destra: $\forall x_0 \in \mathbb{R} \,:\, \lim_{x \downarrow x_0} F_X(x) = F_X(x_0)$;
                    \item il limite destro ($x \rightarrow +\infty$) di $F_X(x)$ vale 1, il limite sinistro ($x \rightarrow -\infty$) vale 0.
                \end{itemize}
            \end{prty}
            \begin{obsv}
                Si può dimostrare che, data una funzione $F$ che soddisfa le Proprietà~\ref{prty:Funzione_ripartizione}, esiste uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ e una variabile aleatoria $X$ definita su di esso che abbia $F$ come funzione di ripartizione; possiamo trattare il problema della A variabile aleatoria $X$ con funzione di ripartizione $F$ senza dover costruire lo spazio di probabilità che contiene $X$.
            \end{obsv}
        \end{obsv}
    \section{Variabili aleatorie discrete}
    \begin{defn}\label{defn:Variabili_aleatorie_discrete}
            La variabile aleatoria $X$ definita su uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ è una variabile aleatoria \textit{discreta} se assume con probabilità 1 i valori all'interno di un insieme $S$ al più numerabile: \[
                P(X \in S) = 1
            .\] 
        \end{defn}
        \begin{defn}\label{defn:Densità_discreta}
            Sia $X$ una variabile aleatoria \underline{discreta} su uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$; allora chiamiamo \textit{densità discreta} di $X$ la funzione definita come segue: \[
                p_X(x) \coloneqq P(X = x)
            .\]
        \end{defn}
        \begin{prty}\label{prty:Densità_discreta}
            Sia  $p_X(x)$ la densità della variabile aleatoria discreta $X$, che assume con probabilità 1 i valori in $S = \{x_k \,:\, k \in I \subset \mathbb{Z}\}$; allora possiamo affermare che:
            \begin{enumerate}
                \item $\forall x \notin S \,:\, p_X(x) = 0 \;\land\; \forall x \in S \,:\, 0 \leq p_X(x) \leq 1$;
                \item $\sum_{k \in I} p_X(x_k) = 1$;
                \item se la funzione di ripartizione di $X$ è $F_X(x)$ allora vale:  \[
                    \forall x \in \mathbb{R} \,:\, F_X(x) = \sum_{k\,:\,x_k \leq x} p_X(x_k)
                ;\]
                \item se possiamo numerare i punti di S prendendo $x_k,\,x_h \in S \,:\, h < k \implies x_h < x_k$ allora vale: \[
                    \forall k \in I \,:\, p_X(x_k) = F_X(x_k) - F_X(x_{k-1})
                ;\]
                \item se consideriamo un sottoinsieme $B \subset \mathbb{R}$ vale: \[
                    P(X \in B) = \sum_{k \,:\, x_k \in B} p_X(x_k)
                .\]
            \end{enumerate}
        \end{prty}
        \begin{proof}
            \hfill
            \begin{enumerate}
                \item Dalla Definizione~\ref{defn:Densità_discreta} segue direttamente che, data la probabilità $p_X(x) = P(X = x)$ e sapendo che $x$ assume valori in un insieme numerabile $S$, otteniamo la prova di $(1)$.
                \item abbiamo enunciato l'ipotesi per cui $P(X \in S) = 1$; possiamo scrivere  \[
                        1 = P(X \in S) = P\left( \bigcup_{k \in I} {X = x_k} \right) = \sum_{k \in I} P(X = x_k) = \sum_{k \in I} p_X(x_k)
                .\]
                \item Osservando che la funzione di ripartizione di $X$ vale $F_X(x) = P(X \leq x)$ e ricordando l'ipotesi $P(X \in S) = 1$ otteniamo:
                \begin{align*}
                    F_X(x) &= P(X \leq x) = P(X \in (-\infty,\,x] \cap S) \\
                           &= P\left( \bigcup_{k \,:\, x_k \leq x} {X = x_k}\right) = \sum_{k \,:\, x_k \leq x} P(X \leq x_k) = \sum_{k \,:\, x_k \leq x} p_X(x_k)
                .\end{align*}
                \item Per il punto (b) dell'Osservazione~\ref{obsv:Funzione_ripartizione} segue che: \[
                    F_X(x_k) - F_X(x_{k-1}) = P(x_{k-1} < X \leq x_k)
                ;\] se i punti di $S$ sono numerati come nell'ipotesi $h < k \implies x_h < x_k$ allora otteniamo: \[
                    P(x_{k-1} < X \leq x_k) = P(X = x_k) \coloneqq p_X(x_k)
                .\]
            \item Riprendiamo l'ipotesi $P(X \in S) = 1$:
                \begin{align*}
                    P(X \in B) &= P(X \in B \cap S) \\
                               &= P\left(\bigcup_{k\,:\,x_k \in B \cap S} \{X = x_k\}\right) = \sum_{k\,:\,x_k \in B \cap S} P(X = x_k) = \sum_{k\,:\,x_k \in B \cap S} p_X(x_k)
                .\qedhere
                \end{align*}
            \end{enumerate}
        \end{proof}
        \begin{obsv}
            Sia $S = \{x_k\,:\,k \in I \subset \mathbb{Z}\} \subset \mathbb{R}$; una funzione $p\,:\, \mathbb{R} \mapsto \mathbb{R}$ è una densità discreta su $S$ se essa soddisfa gli assiomi $(1)$ e $(2)$  della Proprietà~\ref{prty:Densità_discreta}.
        \end{obsv}
    \section{Densità notevoli}
        \subsection{Binomiale}
            \begin{defn}\label{defn:Densità_Binomiale}
                Definiamo la variabile aleatoria $X$ come il numero di successi ottenuti in $n$ prove di Bernoulli; tale variabile aleatoria potrà assumere solamente i valori $0,\, \ldots,\, n$ (è una variabile aleatoria discreta).
                La sua densità vale:
                \begin{equation}\label{eq:Densità_Binomiale}
                    p_X(k) = P(X = k) = \begin{cases}
                        \binom{n}{k}\cdot p^k\cdot (1-p)^{n-k} & \text{se $k \in {0,\, \ldots,\, n}$;}\\
                        0 & \text{se $k \notin {0,\, \ldots,\, n}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Binomiale} \textit{densità binomiale di parametri $n$ e $p$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{B}i(n,\,p)
                .\]
            \end{defn}
            \begin{defn}\label{defn:Densità_Bernoulliana}
                Consideriamo una variabile aleatoria con densità binomiale $X \sim \mathcal{B}i(n,\,p)$ dove $n = 1$; questa variabile rappresenta il numero di successi in una sola prova, ovvero $X \in {0,\, 1}$ e la sua densità vale:
                \begin{equation}\label{eq:Densità_Bernoulliana}
                    \begin{cases}
                        1-p & \text{se $k=0$;} \\
                        p & \text{se $k=1$;} \\
                        0 & \text{se $k \notin {0,\, 1}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Binomiale} \textit{densità bernoulliana di parametro $p$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{B}e(p)
                .\] 
            \end{defn}
            \begin{obsv}
                La variabile aleatoria costante di valore 1 si indica come una variabile aleatoria con densità bernoulliana di parametro 0 ($X \equiv 0 \implies X \sim \mathcal{B}e(0)$); la variabile aleatoria costante di valore 0 si indica come una variabile aleatoria con densità bernoulliana di parametro 1 ($X \equiv 1 \implies X \sim \mathcal{B}e(1)$).
            \end{obsv}
        \subsection{Geometrica}
            \begin{defn}
                Definiamo la variabile aleatoria $X$ l'istante di tempo discreto in cui si verifica un evento, e tale evento sia indipendente dal tempo al quale si verifica; fissato un istante di tempo $k$ possiamo scrivere: \[
                    \forall k \in \mathbb{N} \,:\, P(X > k + 1 | X > k) = P(X > 1)
                .\] Se conosciamo la probabilità $q \coloneqq P(X > 1)$ possiamo ottenere la densità di $X$; usiamo \eqref{eq:Formula_probabilità_condizionata} per riscrivere $q$: \[
                    \forall k \in \mathbb{N} \,:\, q = P(X > 1) = \frac{P(X > k + 1 \cap X > k)}{P(X > k)} = \frac{P(X > k + 1)}{P(X > k)}
                .\] Ora invertiamo la precedente in questo modo:
                \begin{align*}
                    \forall k \in \mathbb{N} \,:\, P(X > k + 1) &= P(X > 1) \cdot P(X > k) \\
                                                        &= P(X > 1)^{k+1} = q^{k+1}
                .\end{align*}
                Sapendo che la funzione di ripartizione di $X$ vale $F_X(k) = 1 - P(X > k) = 1 - q^k$, possiamo ottenere la densità usando il punto $(4)$ della Proprietà~\ref{prty:Densità_discreta}: \[
                    P(X = k) = F_X(k) - F_X(k-1) = q^{k-1} - q^k = q^{k-1}(1-q)
                .\] Definendo l'\textit{intensità di guasto} come la quantità $p \coloneqq 1-q = P(X \leq 1)$ otteniamo la seguente scrittura della densità:
                \begin{align*}
                    P(X = k) = p \cdot (1-p)^{k-1} & &\forall k \in \mathbb{N}
                .\end{align*}
            \end{defn}
            \begin{obsv}
                Richiamiamo la Definizione~\ref{defn:Serie_geometrica}, e dalla somma della serie geometrica otteniamo: \[
                    P(X \in \mathbb{N}) = \sum_{k=1}^{\infty} P(X = k) = \sum_{k=1}^{\infty} p \cdot (1-p)^{k-1} = p \cdot \sum_{k=0}^{\infty} (1-p)^k = p \cdot \frac{1}{1-(1-p)} = 1
                .\] 
            \end{obsv}
            \begin{defn}
                Dalla precedente osservazione e dalla Definizione~\ref{defn:Densità_discreta} concludiamo che $X$ è una variabile aleatoria con la seguente densità:
                \begin{equation}\label{eq:Densità_Geometrica}
                    p_X(k) = \begin{cases}
                        p \cdot (1-p)^{k-1} & \text{se $k \in \mathbb{N}$;} \\
                        0 & \text{se $k \notin \mathbb{N}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Geometrica} \textit{densità geometrica di parametro $p$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{G}(p)
                .\] 
            \end{defn}
        \subsection{Poisson}
            \begin{defn}
                Consideriamo una variabile aleatoria $X \sim \mathcal{B}i(n,\,p)$ con parametro $n \gg 1$ e parametro  $p \ll 1 \land p \in (0,\, 1)$; definiamo inoltre $\lambda \coloneqq n \cdot p$, il quale non dovrà risultare eccessivamente grande (rispetto a $n$).

                Nelle ipotesi appena dettate, perché con un numero grande $n$ di prove indipendenti, aventi ciascuna probabilità di successo $p$ bassa, si abbia un successo, una condizione fondamentale è il valore di $\lambda$, legato alla densità della variabile aleatoria nel modo seguente: \[
                    X \sim \mathcal{B}i(n,\, \lambda / n)
                .\] La probabilità sottostante si scrive come:
                \begin{align*}
                    P(X = x) &= \binom{n}{k} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n}\right)^{n-k} \\
                             &= \frac{n!}{(n-k)!k!} \cdot \left(\frac{\lambda}{n}\right)^k \cdot \left(1-\frac{\lambda}{n}\right)^{n-k} \\
                             &= \underset{(1)}{\underbrace{\frac{n!}{(n-k)!n^k}}} \cdot \underset{(2)}{\underbrace{\left(1-\frac{\lambda}{n}\right)^{-k}}} \cdot \frac{\lambda^k}{k!}\underset{(3)}{\underbrace{\left(1-\frac{\lambda}{n}\right)^{n}}}
                .\end{align*}
                Analizziamo i tre termini evidenziati, al limite per $n$ grande:
                \begin{enumerate}
                    \item $\lim_{n \to \infty} \frac{n!}{(n-k)!n^k} = 1$;
                    \item $\lim_{n \to \infty} \left(1-\frac{\lambda}{n}\right)^{-k} = 1$;
                    \item $\lim_{n \to \infty} \left(1-\frac{\lambda}{n}\right)^{n} = e^{-\lambda}$.
                \end{enumerate}
                Concludiamo che la densità può essere approssimata nel modo seguente, sotto le nostre ipotesi:
                \begin{align}\label{eq:Approssimazione_Binomiale_Poisson}
                        P(X = k) \simeq \frac{\lambda^k}{k!} \cdot e^{-\lambda} & &k \in \mathbb{N},\, \lambda = n \cdot p
                    .
                \end{align}

                Per $\lambda > 0$ possiamo dire che $X$ è una variabile aleatoria con la seguente densità:
                \begin{equation}\label{eq:Densità_Poisson}
                    p_X(k) = \begin{cases}
                        \frac{e^{-k}\lambda^k}{k!} & \text{se $k \in \mathbb{N}$;} \\
                        0 & \text{se $k \notin \mathbb{N}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Poisson} \textit{densità di Poisson di parametro $\lambda$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{P}(\lambda)
                .\] 
            \end{defn}
            \begin{obsv}
                Possiamo usare \eqref{eq:Approssimazione_Binomiale_Poisson} per il calcolo approssimato di $P(X = k)$ quando abbiamo:
                \begin{itemize}
                    \item $X \sim \mathcal{B}i(n,\,p)$;
                    \item $n \gg 1$;
                    \item $p \ll 1$.
                \end{itemize}
                In questo modo si evita il calcolo dei coefficienti binomiali per ciascun $k$.
            \end{obsv}
        \subsection{Ipergeometrica}
            \begin{defn}
                Consideriamo una variabile aleatoria $X$ che conta in numero di successi in $n$ prove, con probabilità di successo determinata da $r$ esiti favorevoli e $b$ esiti sfavorevoli; inoltre, ogni prova determina l'estrazione dallo spazio campionario di un $r$ o di un $b$.
                Ricaviamo la seguente considerazione: \[
                    X < \scriptstyle\text{MIN}\textstyle(n,\,r) \land X > \scriptstyle\text{MAX}\textstyle(0,\,n-b) \implies X \in S = \{\scriptstyle\text{MAX}\textstyle(0,\,n-b),\, \scriptstyle\text{MAX}\textstyle(0,\,n-b) + 1,\, \ldots,\, \scriptstyle\text{MIN}\textstyle(n,\,r)\}
                .\] Scegliendo un $k \in S$ possiamo calcolare la densità $P(X = k)$ come casi favorevoli su casi possibili:
                \begin{equation}\label{eq:Densità_Ipergeometrica}
                    p_X(k) = P(X = k) = \begin{cases}
                        \frac{\binom{r}{k} \cdot \binom{b}{n-k}}{\binom{r+b}{n}} & \text{se $k \in S$;} \\
                        0 & \text{se $k \notin S$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Ipergeometrica} \textit{densità ipergeometrica di parametri $b+r$, $r$ e $n$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{I}(b+r,\, r,\, n)
                .\] 
            \end{defn}
            \begin{obsv}
                Se il valore $r+b$ è molto grande (tende a $+\infty$) allora la dipendenza tra le prove successive si attenua e, in opportune condizioni, è possibile approssimare una variabile aleatoria $X$ con densità ipergeometrica tramite la densità binomiale: \[
                    X \sim \mathcal{I}(b+r,\, r,\, n) \simeq \mathcal{B}i(n,\, r / (r+b))
                .\] 
            \end{obsv}
    \section{Variabili aleatorie continue}
        \begin{defn}\label{defn:Variabile_aleatoria_continua}
            Consideriamo una variabile aleatoria $X$ definita su uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$; essa è chiamata variabile aleatoria \textit{assolutamente continua} se esiste una funzione $f_X\,:\, \mathbb{R} \mapsto \mathbb{R^+}$, che sia integrabile e la primitiva della funzione di ripartizione di $X$; inoltre deve essere possibile scrivere $F_X(x)$ nel modo seguente:
            \begin{equation}
                F_X(x) = \int_{-\infty}^{x} f_X(s)\, ds 
            \end{equation}
            Chiamiamo \textit{densità} di $X$ la funzione $f_X(x)$.
        \end{defn}
        \begin{prty}\label{prty:Variabile_aleatoria_continua}
            Se $f_x(x)$ è la densità di una variabile aleatoria $X$ assolutamente continua, allora possiamo affermare che:
            \begin{enumerate}
                \item $\int_{\mathbb{R}} f_X(x)\, dx = 1$;
                \item se risulta che la primitiva di $f_X(x)$ è la funzione di ripartizione di $X$, allora vale: \[
                        \forall x \in \mathbb{R} \,:\, \exists F^{\prime}_X(x) \implies f_X(x) = F_X^{\prime}(x)
                ;\]
            \item se presi $a,\, b \in \mathbb{R}$ si verifica che $-\infty < a < b < +\infty$, allora vale:
                \begin{align*}
                    P\left(X \in (a,\,b)\right) &= P\left(X \in (a,\,b]\right) = P\left(X \in [a,\,b)\right) = P\left(X \in [a,\,b]\right) \\
                                   &= \int_{a}^{b} f_X(x)\, dx
                .\end{align*}
            \end{enumerate}
            \begin{proof}
                \hfill
                \begin{enumerate}
                    \item $1 = \lim_{x \to +\infty} F_X(x) = \lim_{x \to +\infty} \left(\int_{-\infty}^{x} f_X(s)\, ds\right) = \int_{\mathbb{R}} f_X(s)\, ds$;
                    \item conseguenza del teorema fondamentale del calcolo integrale;
                    \item sapendo che $\forall x \in \mathbb{R} \,:\, P(X = x) = 0$ otteniamo: \[
                        P(X \in (a,\,b]) = P({X \in (a,\,b)} \cup {X = b}) = P(X \in (a,\,b)) + \cancel{P(X = b)} = P(X \in (a,\,b))
                    .\] In modo analogo possiamo dimostrare che vale:\[
                        P(X \in (a\,b)) = P(X \in [a\,b)) = P(X \in [a\,b]) 
                    .\] Consideriamo l'intervallo $(a\,b]$:
                    \begin{align*}
                        P(X \in (a,\,b]) &= P(\{X \in (-\infty,\,b]\} \backslash \{X \in (-\infty,\,a]\}) \\
                                      &= P(\{X \in (-\infty,\,b]\} - \{X \in (-\infty,\,a]\}) \\
                                      &= F_X(b) - F_X(a) = \int_{-\infty}^{b} f_X(x)\, dx - \int_{-\infty}^{a} f_X(x)\, dx \\
                                      &= \int_{a}^{b} f_X(x)\, dx \qedhere
                    .\end{align*}
                \end{enumerate}
            \end{proof}
            \begin{prty}\label{prty:Assoluta_continuità}
                Consideriamo il punto $(2)$ della Proprietà~\ref{prty:Variabile_aleatoria_continua}.

                Sia $X$ una variabile aleatoria e $F_X(x)$ la sua funzione di ripartizione; se $F_X(x)$ è continua e derivabile con continuità per ogni $x$ in $\mathbb{R}$ \--- eccetto al più un insieme finito di punti $B \coloneqq \{x_1,\,\ldots,\, x_n\} \subset \mathbb{R}$; allora $X$ è una variabile aleatoria \textit{assolutamente continua} e la funzione $f_X(x) = F^{\prime}_X(x)$, definita $\forall x \notin B$ in modo arbitrario su $B$, è una densità per $X$.
            \end{prty}
            \begin{obsv}
                Consideriamo il punto $(3)$ della Proprietà~\ref{prty:Variabile_aleatoria_continua}.

                Sia $X$ una variabile aleatoria \underline{assolutamente continua} con densità $f_X(x)$ e l'insieme $B \subset \mathbb{R}$ sia tale che $B = B_1 \cup B_2 \cup \dotsm$ dove gli intervalli $B_k,\, k = 0,\,1,\,\ldots$ sono disgiunti; allora otteniamo: \[
                    P(X \in B) = \int_{B} f_X(x)\, dx = \sum_{k=1}^{+\infty} \int_{B_k} f_X(x)\, dx
                .\] 
            \end{obsv}
            \begin{obsv}
                Una funzione $f\,:\, \mathbb{R} \mapsto \mathbb{R}$ è una \textit{densità} su $\mathbb{R}$ se valgono:
                \begin{enumerate}
                    \item $f(x)$ è integrabile e $f(x) \geq 0$, per ogni $x$ in $\mathbb{R}$;
                    \item $\int_{\mathbb{R}} f(x)\, dx = 1$.
                \end{enumerate}
            \end{obsv}
        \end{prty}
    \section{Densità continue notevoli}
        \subsection{Uniforme}
            \begin{defn}\label{defn:Densità_uniforme}
                Sia $X$ un reale scelto casualmente nell'intervallo $(0,\,1]$; essendo scelto casualmente, la probabilità $P(X \leq \frac{1}{2})$ è uguale alla probabilità $P(X > \frac{1}{2})$.

                Possiamo verificare quanto appena affermato considerando che:
                \begin{itemize}
                    \item $(0,\,1] = (0,\,\frac{1}{2}] \cup (\frac{1}{2},\,1]$;
                    \item $P\left(X \in (0,\,\frac{1}{2}]\right) = P\left(X \in (\frac{1}{2},\,1]\right)$;
                    \item $P\left(X \in (0,\,\frac{1}{2}]\right) + P\left(X \in (\frac{1}{2},\,1]\right) = 1$.
                \end{itemize}
                Ripetendo questo ragionamento per un numero $x$ di sottoinsiemi di $(0,\,1]$ otteniamo la funzione di ripartizione di $X$: \[
                    F_X(x) = \begin{cases}
                        0 & \text{se $x < 0$;} \\
                        x & \text{se $0 \leq x < 1$;} \\
                        1 & \text{se $x \geq 1$.}
                    \end{cases}
                \] Dato che $F_X(x)$ è derivabile con continuità tranne che in 0 e 1, per la Proprietà~\ref{prty:Assoluta_continuità} la variabile $X$ è assolutamente continua, con la seguente densità:
                \begin{equation}\label{eq:Densità_uniforme} 
                    F_X(x)^{\prime} = f_X(x) = \begin{cases}
                        0 & \text{se $x < 0$;} \\
                        1 & \text{se $0 < x < 1$;} \\
                        0 & \text{se $x > 1$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_uniforme} \textit{densità uniforme} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{U}(0,\, 1)
                .\]
            \end{defn}
        \subsection{Esponenziale}
            \begin{defn}
                Consideriamo un apparecchio \underline{non} soggetto a usura e funzionante, il quale abbia una certa probabilità di guastarsi; chiamato $T$ l'istante di tempo in cui si guasta, esso sarà ancora funzionante dopo $s$ secondi con probabilità $P(T > s)$.

                Per come abbiamo appena definito $T,\,s$ e la probabilità, per l'assenza di usura otteniamo: \[
                    P(T > t + s | T > s) = P(T > s)
                .\] Dato che la probabilità di guastarsi è indipendente dal numero degli istanti di tempo in cui l'apparecchio funziona, possiamo scrivere: \[
                P(T > s) = \frac{P(\{T > t + s\} \cap \{T > t\})}{P(T > t)} = \frac{P(T > t+s)}{P(T > t)}
                .\] Dalla precedente ricaviamo che: \[
                P(T > t + s) = P(T > t) \cdot P(T > s)
            .\] Se definiamo $\overline{F}(t) \coloneqq P(T > t)$ otteniamo: \[
                \overline{F}(t + s) = \overline{F}(t) \cdot \overline{F}(s)
            .\] L'unica funzione che risolve questa equazione funzionale è $e^{\alpha t}$; allora la funzione di ripartizione si ricava dalla proprietà $P(T \leq t) = 1 - e^{\alpha t}$ per $t \geq 0$, e osservando che $\alpha < 0$ otteniamo la funzione di ripartizione di $T$: \[
            F_T(t) = \begin{cases}
                0 & \text{se $t < 0$;} \\
                1 - e^{-\mu t} & \text{se $t \geq 0 \land \mu > 0$.}
            \end{cases}
            \] Per la Proprietà~\ref{prty:Assoluta_continuità} la variabile $T$ è assolutamente continua, con la seguente densità:
            \begin{equation}\label{eq:Densità_esponenziale} 
                F_T(t) = \begin{cases}
                    0 & \text{se $t < 0$;} \\
                    \mu e^{-\mu t} & \text{se $t > 1$.}
                \end{cases}
           \end{equation}
            Chiamiamo la \eqref{eq:Densità_esponenziale} \textit{densità esponenziale} o in modo equivalente indichiamo: \[
                T \sim \mathcal{E}(\mu)
            .\]
            \end{defn}
        \subsection{Normale Standard}
            \begin{defn}
                Consideriamo una variabile aleatoria $Z$ che sia \underline{assolutamente} continua su uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$; diremo che $Z$ ha \textit{densità normale standard} se la sua densità vale:
                \begin{align}\label{eq:Densità_normale_standard} 
                    \varphi(z) = \frac{1}{\sqrt{2\pi}} \cdot e^{-z^2/2} & &\forall z \in \mathbb{R}
                .\end{align}
                In modo equivalente indichiamo: \[
                    Z \sim \mathcal{N}(0,\, 1)
                .\]
            \end{defn}
            \begin{obsv}
                La funzione \eqref{eq:Densità_normale_standard} risulta simmetrica intorno all'asse $y$, con massimo in 0; sapendo ciò, possiamo calcolare la probabilità $Z \in (-z,\, z)$ nel modo seguente:
                \begin{align*}
                    P(-z < Z < z) &= \int_{-z}^{z} \varphi(x)\, dx = \frac{1}{\sqrt{2\pi}} \cdot \int_{-z}^{z} e^{-x^2/2}\, dx = \frac{2}{\sqrt{2\pi}} \cdot \int_{0}^{z} e^{-x^2/2}\, dx \\
                                  &= \frac{2}{\sqrt{\pi}} \cdot \int_{0}^{z /\sqrt{2}} e^{-y^2}\, dy & [y = x /\sqrt{2}] 
                .\end{align*}
                Chiamiamo la funzione ottenuta \textit{funzione di errore}, la quale è così definita per ogni $z$ positivo, e la indichiamo con $\text{erf}(z /\sqrt{2})$.
            \end{obsv}
            \begin{prty}
                La densità normale standard \eqref{eq:Densità_normale_standard} di una variabile aleatori $Z \sim \mathcal{N}(0,\,1)$ determina la seguente funzione di ripartizione per $Z$:
                \begin{equation}\label{eq:Ripartizione_normale_standard}
                    \mathbf{\Phi}(z) = \frac{1}{\sqrt{2\pi}} \cdot \int_{-\infty}^{z} e^{-x^2 /2}\, dx
                \end{equation}
            \end{prty}
            \begin{obsv}
                Per la simmetria di $\varphi(z)$ osservata prima, otteniamo: \[
                    \forall z \in \mathbb{R} \,:\, \mathbf{\Phi}(z) = 1 - \mathbf{\Phi}(-z)
                .\] 
            \end{obsv}
            \begin{proof}
                \hfill
                \begin{align*}
                    \mathbf{\Phi}(z) &= 1 - P(Z > z) = 1 - P(Z > z) - P(Z = z) \\
                                     &= 1 - P(Z \geq z) = 1 - P(Z \leq -z) \\
                                     &= 1 - \mathbf{\Phi}(-z)
                .\end{align*}
            \end{proof}
        \subsection{Gaussiana}
            \begin{note}
                Per comprendere le proposizioni seguenti, fare riferimento alle sezioni §~\ref{sec:Valore_atteso} e §~\ref{sec:Varianza}.
            \end{note}
    \section{Funzioni di variabili aleatorie}
        \begin{defn}[discreta]\label{defn:Funzioni_variabili_aleatorie_discrete}
            Consideriamo una variabile aleatoria discreta $X$ con densità $p_X(x)$; valga inoltre $P(X \in S) = 1$, dove $S = \{x_k \,:\, k \in I\}$ e $I \subset Z$.

            Prendiamo $g\,:\, S \mapsto \mathbb{R}$ e valga $g(S) = \{g(x) \,:\, x \in S\}$; se definiamo $Y \coloneqq g(X)$, allora $Y$ è una variabile aleatoria discreta con valori in $g(S)$ ovvero $P(Y \in g(S)) = 1$, e la sua densità vale: \[
                p_Y(y) = \begin{cases}
                    \sum_{k \,:\, g(x_k) =y} p_X(x_k) & \text{se $y \in g(S)$;} \\
                    0 & \text{se $y \notin g(S)$.}
                \end{cases}
            .\]
        \end{defn}
        \begin{obsv}
            La Definizione~\ref{defn:Funzioni_variabili_aleatorie_discrete} afferma che, a partire da una variabile aleatoria discreta $X$, possiamo ottenere sotto certe condizioni la funzione $g(X)$ che è ancora una variabile aleatoria discreta; inoltre, la sua densità è univocamente determinata da quella di $X$.

            Questo implica la seguente: \[
                p(X) = p(W) \implies g(X) = g(W)
            .\] 
        \end{obsv}
        \begin{defn}[continua]\label{defn:Funzioni_variabili_aleatorie_continue}
            Consideriamo una variabile aleatoria assolutamente continua $X$ con densità $f_X(x)$; valga inoltre $S \in \mathbb{R} \,:\, P(X \in S) = 1$, $g(x)$ sia differenziabile con continuità su $S$ e $\forall x \in S \,:\, g^{\prime} \neq 0$.
            
            Sia $g^{-1}(x)$ la funzione inversa di $g(x)$ e valga $g(S) = \{g(x) \,:\, x \in S\}$; allora $Y = g(X)$ è una variabile aleatoria assolutamente continua con densità: \[
                f_Y(y) = \begin{cases}
                    f_X(g^{-1}(y)) \cdot \left|(g^{-1}(y))^{\prime}\right| & \text{se $y \in g(S)$;} \\
                    0 & \text{se $y \notin g(S)$.}
                \end{cases}
            \]
        \end{defn}
    \section{Valore atteso}\label{sec:Valore_atteso}
    \begin{defn}[discreto]\label{defn:Valore_atteso_discreto}
            Sia $X$ una variabile aleatoria discreta con valori in $S = \{x_k \,:\, k \in I\}$ dove $I \subset \mathbb{Z}$, e sia $p_X(x)$ la sua densità; se abbiamo: \[
                \sum_{k \in I} \left|x_k\right| \cdot p_X(x_k) < +\infty
            ,\] allora chiamiamo \textit{media} o \textit{valore atteso} di $X$ la seguente espressione:
            \begin{equation}\label{eq:Valore_atteso_discreto}
                \text{E}(X) \coloneqq \sum_{k \in I}x_k \cdot p_X(x_k)
            ;\end{equation}
            se invece questo non vale, allora diciamo che $X$ non ammette valore atteso.
        \end{defn}
        \begin{obsv}
            Anche se $X$ è una variabile aleatoria discreta, il fatto che abbia valore atteso dipende dalla convergenza delle somme nell'equazione \eqref{eq:Valore_atteso_discreto}. Questo è sempre vero se $I$ è un insieme finito, poiché in tal caso $X$ assumerà un numero finito di valori.

            Per la convergenza delle somme \eqref{eq:Valore_atteso_discreto} anche il valore atteso $\text{E}(X)$ sarà un valore finito; esso dipenderà unicamente dalla densità $p_X(x)$.
        \end{obsv}
        \begin{defn}[continuo]\label{defn:Valore_atteso_continuo}
            Sia $X$ una variabile aleatoria assolutamente continua e $f_X(x)$ la sua densità; se abbiamo: \[
                \int_{\mathbb{R}} |x| \cdot f_X(x)\, dx < +\infty 
            ,\] allora chiamiamo \textit{media} o \textit{valore atteso}  di $X$ la seguente espressione:
            \begin{equation}\label{eq:Valore_atteso_continuo}
                \text{E}(X) \coloneqq \int_{\mathbb{R}} x \cdot f_X(x)\, dx
            ;\end{equation}
            se invece questo non vale, allora diciamo che $X$ non ammette valore atteso.
        \end{defn}
        \begin{defn}[discreta]
            Sia $X$ una variabile aleatoria \underline{discreta} con valori in $S = \{x_k \,:\, k \in I\}$ e $I \subset \mathbb{Z}$, e densità $p_X(x)$; sia inoltre $g()$ una funzione reale  e definiamo $T \coloneqq  g(X)$.

            Se vale: \[
                \sum_{k \in I} g(x_k)  \cdot p_X(x_k)
            ,\] allora la funzione $Y$ ammette valore atteso ed esso vale:
            \begin{equation}\label{eq:Valore_atteso_funzione_discreta}
                \text{E}(Y) = \sum_{k \in I} g(x_k) \cdot p_X(x_k)
            .\end{equation}
        \end{defn}
        \begin{defn}[continua]
            Consideriamo $X$ una variabile aleatoria \underline{assolutamente continua} con densità $f_X(x)$ e $g(X)$ una funzione reale tale che $Y = g(X)$ sia una variabile aleatoria.
            Se vale: \[
                \int_{\mathbb{R}} \left|g(x)\right| \cdot f_X(x)\, dx < +\infty
            ,\] allora la funzione $Y$ ammette valore atteso ed esso vale:
            \begin{equation}\label{eq:Valore_atteso_funzione_continua}
                \text{E}(Y) = \int_{\mathbb{R}} g(x) \cdot f_X(x)\, dx
            .\end{equation}
        \end{defn}
        \begin{prty}\label{prty:Valore_atteso}
            Sia $X$ una variabile aleatoria definita sullo spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$.
            \begin{enumerate}
                \item $P(X = c) = 1 \implies \text{E}(X) = c$ (\textit{coerenza});\label{itm:Coerenza_valore_atteso}
                \item sia $X$ una variabile aleatoria e $B \subset \mathbb{R} \,:\, \{X \in B\} \in \mathscr{F}$; allora vale $\text{E}(\mathbf{F}_B(X)) = P(X \in B)$;
                \item sia $X$ una variabile aleatoria che ammette valore atteso $\text{E}(X)$ e $\alpha$ una costante, allora vale: $\text{E}(\alpha \cdot X) = \alpha \cdot \text{E}(X)$ (\textit{linearità});\label{itm:Linearità_valore_atteso_prodotto}
                \item sia $X$ una variabile aleatoria e $g(),\, h()$ due funzioni tali che esistano i loro valori attesi $\text{E}(g(X)),\, \text{E}(h(X))$; allora vale: $\text{E}(g(X)+h(X)) = \text{E}(g(X)) + \text{E}(h(X))$ (\textit{linearità});\label{itm:Linearità_valore_atteso_somma}
                \item sia $X$ una variabile aleatoria tale che $P(X > 0) = 1$ ed esista il suo valore atteso $\text{E}(X)$, allora esso vale $\text{E}(X) \geq 0$; se inoltre il valore atteso è nullo, allora otteniamo $P(X = 0) = 1$ (\textit{positività});\label{itm:Positività_valore_atteso}
                \item $a,\,b \in \mathbb{R} \,:\, P(a \leq X \leq B) = 1 \implies a \leq \text{E}(X) \leq b$ (\textit{internalità});\label{itm:Internalità_valore_atteso}
                \item siano $g(),\,h()$ funzioni reali che ammettano valore atteso $\text{E}(g(x)),\,\text{E}(h(X))$; allora vale: $P(h(X) \geq g(X)) = 1 \implies \text{E}(h(X)) \geq \text{E}(g(X))$.
            \end{enumerate}
        \end{prty}
        \begin{proof}
            \hfill
            \begin{enumerate}
                \item $P(X = c) = 1 \implies \text{E}(X)= c \cdot P(X = c) = c$.
                \item $Y \coloneqq  \mathbf{1}_B(X) \implies Y \sim \mathcal{B}e(p) \land p = P(Y = 1) = P(X \in B) \implies \text{E}(Y) = P(X \in B)$.
                \item Supponiamo $X$ assolutamente continua; per la Definizione~\ref{defn:Valore_atteso_continuo} vale: \[
                    \text{E}(\alpha \cdot X) = \int_{\mathbb{R}} \alpha x \cdot f_X(x)\, dx = \alpha \int_{\mathbb{R}} x \cdot f_X(x)\, dx = \alpha \text{E}(X)
                .\] Nel caso di una variabile aleatoria discreta sfruttiamo la Definizione~\ref{defn:Valore_atteso_discreto} e dimostriamo in modo analogo.
                \item Supponiamo $X$ assolutamente continua; per la Definizione~\ref{defn:Valore_atteso_continuo} vale:
                \begin{align*}
                    \text{E}(g(X) + h(X)) &= \text{E}(X^2 + 2X) = \int_{\mathbb{R}} (x^2 + 2x) \cdot f_X(x)\, dx = \int_{\mathbb{R}} x^2 \cdot f_X(x),\, dx + \int_{\mathbb{R}} 2x \cdot f_X(x),\, dx \\
                                          &= \text{E}(X^2) + \text{E}(2X) = \text{E}(g(X)) + \text{E}(h(X))
                .\end{align*}
                \item Supponiamo $X$ discreta; poiché $P(X \geq 0)=1$ allora $\forall x < 0 p_X(x) = 0$ da cui otteniamo: \[
                    \text{E}(X) = \sum_{k \,:\, x_k \geq 0} x_k \cdot p_X(x_k) \geq 0
                .\] Si dimostra analogamente il caso di $X$ assolutamente continua.
                \item Sapendo che: \[
                    P(a \leq X \leq b) = 1 \implies \exists\, \text{E}(X)
                ,\] osserviamo che $P(X -a \geq 0) = 1$ e per i punti \eqref{itm:Coerenza_valore_atteso}, \eqref{itm:Linearità_valore_atteso_somma} e \eqref{itm:Positività_valore_atteso} della Proprietà~\ref{prty:Valore_atteso} si ha: \[
                0 \leq \text{E}(X - a)= \text{E}(X) + \text{E}(-a) = \text{E}(X) - a \implies \text{E}(X) \geq a
            .\] Ripetendo lo stesso ragionamento per $P(b - X \geq 0) = 1$, concludiamo la dimostrazione anche per $\text{E}(X) \leq b$.
                \item La dimostrazione si realizza come nel punto precedente, usando due funzioni al posto delle due costanti. \qedhere
            \end{enumerate}
        \end{proof}
    \section{Varianza}\label{sec:Varianza}
        \begin{defn}\label{defn:Varianza}
            Sia $X$ una variabile aleatoria che ammetta valore atteso $\text{E}(X)$; se esiste il valore atteso della distanza al quadrato tra $X$ e il suo valore atteso ($\text{E}((X - \text{E}(X))^2)$), allora definiamo: \[
                \text{Var}(X) \coloneqq \text{E}((X - \text{E}(X))^2)
            ;\] chiamiamo \textit{varianza} di $X$ la quantità $\text{Var}(X)$, mentre la sua radice quadrata $\sqrt{\text{Var}(X)}$ prende il nome di \textit{deviazione standard}.
        \end{defn}
        \begin{obsv}
            Dalle Definizione~\ref{defn:Valore_atteso_discreto} e Definizione~\ref{defn:Valore_atteso_continuo} si deduce che:
            \begin{itemize}
                \item data una variabile aleatoria discreta $X$ con media $\mu = \text{E}(X)$ e densità $p_X(x)$, la sua varianza si ottiene come $\sum_{k} (x_k - \mu)^2 \cdot p_X(x_k)$;
                \item data una variabile aleatoria assolutamente continua con media $\mu = \text{E}(X)$ e densità $f_X(x)$, la sua varianza si ottiene come $\int_{\mathbb{R}} (x - \mu)^2 \cdot f_X(x)\, dx$.
            \end{itemize}
        \end{obsv}
        \begin{prty}
            Consideriamo una variabile aleatoria $X$:
            \begin{enumerate}
                \item $\text{Var}(X)=0 \iff \exists c \,:\, P(X = c) = 1 \implies \text{E}(X) = c$;
                \item $\exists\, \text{Var}(X) \land \alpha \in \mathbb{R} \implies \text{Var}(\alpha \cdot X) = \alpha^2 \cdot \text{Var}(X)$;
                \item $\exists\, \text{Var}(X) \land \beta \in \mathbb{R} \implies \text{Var}(X + \beta) = \text{Var}(X)$;
                \item $\exists\, \text{Var}(X) \implies \exists\, \text{E}(X^2) \land \text{Var}(X) = \text{E}(X^2) - \text{E}(X)^2$.
            \end{enumerate}
        \end{prty}
        \begin{proof}
            \hfill
            \begin{enumerate}
                \item Se $P(X = c) = 1$ allora deve valere (per il punto \eqref{itm:Coerenza_valore_atteso} della Proprietà~\ref{prty:Valore_atteso} e poi dalla Definizione~\ref{defn:Varianza}): \[
                    \text{E}(X) = c \land \text{Bar}(X) = \text{E}((c-c)^2) = \text{E}(0) = 0
                .\] Al contrario, dato che $P(X -\text{E}(X))^2 \geq 0$: \[
                \text{Var}(X) = \text{E}((X - \text{E}(X))^2) = 0 \implies P((X - \text{E}(X))^2 = 0) = 1 \iff P(X = \text{E}(X)) = 1
                .\]
                \item Dal punto \eqref{itm:Linearità_valore_atteso_prodotto} della Proprietà~\ref{prty:Valore_atteso} abbiamo che:
                \begin{align*}
                        \text{Var}(\alpha \cdot X) &= \text{E}((\alpha \cdot X - \text{E}(\alpha \cdot X))^2) = \text{E}((\alpha \cdot X - \alpha \cdot \text{E}(X))^2) \\
                                          &= \text{E}(\alpha^2 \cdot (X - \text{E}(X))^2) = \alpha^2 \cdot \text{E}((X - \text{E}(X))^2)= \alpha^2 \cdot \text{Var}(X)
                .\end{align*}
                \item Dal punto \eqref{itm:Linearità_valore_atteso_somma} della Proprietà~\ref{prty:Valore_atteso} abbiamo che:
                \begin{align*}
                    \text{Var}(X + \beta) &= \text{E}((X+\beta -\text{E}(X+\beta))^2) = \text{E}((X \cancel{+\beta} -\text{E}(X) \cancel{-\beta})^2) \\
                                          &= \text{E}((X - \text{E}(X))^2) = \text{Var}(X)
                .\end{align*}
                \item Dal punto \eqref{itm:Positività_valore_atteso} della Proprietà~\ref{prty:Valore_atteso} abbiamo che:
                \begin{align*}
                    \text{E}(X^2) &= \text{E}((X - \cancel{\text{E}(X)} + \cancel{\text{E}(X)})^2) \leq \text{E}\left(2\cdot(X - \text{E}(X))^2 + 2\cdot\text{E}(X)^2\right) \\
                                  &= 2 \cdot \text{E}((X - \text{E}(X))^2) + 2\cdot\text{E}(X)^2 \\
                                  &= 2\cdot\text{Var}(X) + 2\cdot\text{E}(X)^2 < +\infty
                .\end{align*}
                Sapendo quindi che $X^2$ ammette media, possiamo dire della varianza:
                \begin{align*}
                    \text{Var}(X) &= \text{E}((X - \text{E}(X))^2) = \text{E}(X^2 - 2X\cdot\text{E}(X) + \text{E}(X)^2) \\
                                  &= \text{E}(X^2) - 2\cdot\text{E}(X\cdot\text{E}(X)) + \text{E}(\text{E}(X)^2) \\
                                  &= \text{E}(X^2) - 2\cdot\text{E}(X)^2 + \text{E}(X)^2 \\
                                  &= \text{E}(X^2) - \text{E}(X)^2 \qedhere
                .\end{align*}
            \end{enumerate}
        \end{proof}
    \section{Disuguaglianza di Chebichev}
        \begin{defn}
            
        \end{defn}
    \section{Trasformazioni affini di variabili aleatorie}
    \section{Standardizzazione di variabile aleatoria}
    \section{Probabilità della normale standard}
    \section{Teorema di De Moivre-Laplace}
        \subsection{Approssimazione normale della binomiale}
        \subsection*{Correzione del continuo}
    \section{Momenti}
    \section{Affidabilità}
        \subsection{Tempi di vita}
        \subsection{Intensità di guasto}
        \subsection{Distribuzione di Weibull}
