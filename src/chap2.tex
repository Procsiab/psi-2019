%! TEX root = main.tex
% Capitolo 2

\chapter{Variabili Aleatorie}
    \section{Variabile aleatoria o casuale}
        \begin{defn}\label{defn:Variabile_aleatoria}
            Consideriamo lo spazio di probabilità $(\Omega,\,\mathscr{F},\,P)$; una \textit{variabile aleatoria} $X$ è una funzione da $\Omega$ in $\mathbb{R}$ tale che: \[
                \forall x \in \mathbb{R} \,:\, \{X \leq x\} \coloneqq \{\omega \in \Omega \,:\, X(\omega) \leq x\} \in \mathscr{F}
            .\]
        \end{defn}
        \begin{prty}\label{prty:Variabile_aleatoria}
            Se $X$ è una variabile aleatoria allora i seguenti insiemi sono eventi, ovvero sottoinsiemi di $\Omega$ che appartengono a $\mathscr{F}$:
            \begin{align*}
                &\{X < x\}, & &\{X \geq x\}, & &\{X > x\}, \\
                &\{x < X < y\}, & &\{x \leq X < y\}, & &\{x < X \leq y\}, \\
                &\{x \leq X \leq y\}, & &\{X = x\}, & &\{X \neq x\}
            .\end{align*}
        \end{prty}
    \section{Funzione di ripartizione}
        \begin{defn}\label{defn:Funzione_ripartizione}
            Sia $X$ una variabile aleatoria definita su uno spazio di probabilità $(\Omega,\,\mathscr{F},\,P)$; chiamiamo \textit{funzione di ripartizione} di $X$ la funzione $F_X\,:\, \mathbb{R} \mapsto [0,\,1]$ definita come: \[
                \forall x \in \mathbb{R} \,:\, F_X(x) \coloneqq P(X \leq x)
            .\]
        \end{defn}
        \begin{obsv}\label{obsv:Funzione_ripartizione}
            Sia $X$ una variabile aleatoria definita sullo spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ e sia dato $x \in \mathbb{R}$ che definisce la funzione di ripartizione $F_X(x) \coloneqq P(X \leq x)$; per il punto $(2)$ della Proprietà~\ref{prty:Spazio_di_probabilità} possiamo scrivere:
            \begin{enumerate}[\indent (a)]
                \item Consideriamo la probabilità inversa della funzione di ripartizione:
                    \begin{align*}
                        P(X > x) &= P(\{\omega \in \Omega \,:\, X(\omega) > x\}) = P(\{\omega \in \Omega \,:\, X(\omega) \leq x\}^{\text{C}}) \\
                                 &= 1 - P(\{\omega \in \Omega \,:\, X(\omega) \leq x\}) \\
                                 &= 1 - P(X \leq x)
                    .\end{align*}
                \item Se invece abbiamo $x,\,y \in \mathbb{R}$ con $x < y$, per il punto $(3)$ della Proprietà~\ref{prty:Proprietà_funzione_probabilità} vale:
                    \begin{align*}
                        P(x < X \leq y) &= P(\{\omega \in \Omega \,:\, x < X(\omega) \leq y\}) \\
                                     &= P(\{\omega \in \Omega \,:\, X(\omega) \leq y\} \backslash \{\omega \in \Omega \,:\, X(\omega) \leq x\}) \\
                                     &= P(\{\omega \in \Omega \,:\, X(\omega) \leq y\} - \{\omega \in \Omega \,:\, X(\omega) \leq x\}) \\
                                     &= P(X \leq y) - P(X \leq x)
                    .\end{align*}
            \end{enumerate}
            Osserviamo che la conoscenza della funzione di ripartizione di $X$ ci permette di calcolare le probabilità di eventi ad essa associati.
            \begin{prty}\label{prty:Funzione_ripartizione}
                Sia $X$ una variabile aleatoria definita sullo spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ e la sua funzione di ripartizione $F_X(x) = P(X \leq x)$; allora possiamo affermare che:
                \begin{itemize}
                    \item $F_X(x)$ è una funzione \textit{monotona non decrescente};
                    \item $F_X(x)$ è \textit{continua} da destra: $\forall x_0 \in \mathbb{R} \,:\, \lim_{x \downarrow x_0} F_X(x) = F_X(x_0)$;
                    \item il limite destro ($x \rightarrow +\infty$) di $F_X(x)$ vale 1, il limite sinistro ($x \rightarrow -\infty$) vale 0.
                \end{itemize}
            \end{prty}
            \begin{obsv}
                Si può dimostrare che, data una funzione $F$ che soddisfa le Proprietà~\ref{prty:Funzione_ripartizione}, esiste uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ e una variabile aleatoria $X$ definita su di esso che abbia $F$ come funzione di ripartizione; possiamo trattare il problema della A variabile aleatoria $X$ con funzione di ripartizione $F$ senza dover costruire lo spazio di probabilità che contiene $X$.
            \end{obsv}
        \end{obsv}
    \section{Variabili aleatorie discrete}
    \begin{defn}\label{defn:Variabili_aleatorie_discrete}
            La variabile aleatoria $X$ definita su uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$ è una variabile aleatoria \textit{discreta} se assume con probabilità 1 i valori all'interno di un insieme $S$ al più numerabile: \[
                P(X \in S) = 1
            .\] 
        \end{defn}
        \begin{defn}\label{defn:Densità_discreta}
            Sia $X$ una variabile aleatoria \underline{discreta} su uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$; allora chiamiamo \textit{densità discreta} di $X$ la funzione definita come segue: \[
                p_X(x) \coloneqq P(X = x)
            .\]
        \end{defn}
        \begin{prty}\label{prty:Densità_discreta}
            Sia  $p_X(x)$ la densità della variabile aleatoria discreta $X$, che assume con probabilità 1 i valori in $S = \{x_k \,:\, k \in I \subset \mathbb{Z}\}$; allora possiamo affermare che:
            \begin{enumerate}
                \item $\forall x \notin S \,:\, p_X(x) = 0 \;\land\; \forall x \in S \,:\, 0 \leq p_X(x) \leq 1$;
                \item $\sum_{k \in I} p_X(x_k) = 1$;
                \item se la funzione di ripartizione di $X$ è $F_X(x)$ allora vale:  \[
                    \forall x \in \mathbb{R} \,:\, F_X(x) = \sum_{k\,:\,x_k \leq x} p_X(x_k)
                ;\]
                \item se possiamo numerare i punti di S prendendo $x_k,\,x_h \in S \,:\, h < k \implies x_h < x_k$ allora vale: \[
                    \forall k \in I \,:\, p_X(x_k) = F_X(x_k) - F_X(x_{k-1})
                ;\]
                \item se consideriamo un sottoinsieme $B \subset \mathbb{R}$ vale: \[
                    P(X \in B) = \sum_{k \,:\, x_k \in B} p_X(x_k)
                .\]
            \end{enumerate}
        \end{prty}
        \begin{proof}
            \hfill
            \begin{enumerate}
                \item Dalla Definizione~\ref{defn:Densità_discreta} segue direttamente che, data la probabilità $p_X(x) = P(X = x)$ e sapendo che $x$ assume valori in un insieme numerabile $S$, otteniamo la prova di $(1)$.
                \item abbiamo enunciato l'ipotesi per cui $P(X \in S) = 1$; possiamo scrivere  \[
                        1 = P(X \in S) = P\left( \bigcup_{k \in I} {X = x_k} \right) = \sum_{k \in I} P(X = x_k) = \sum_{k \in I} p_X(x_k)
                .\]
                \item Osservando che la funzione di ripartizione di $X$ vale $F_X(x) = P(X \leq x)$ e ricordando l'ipotesi $P(X \in S) = 1$ otteniamo:
                \begin{align*}
                    F_X(x) &= P(X \leq x) = P(X \in (-\infty,\,x] \cap S) \\
                           &= P\left( \bigcup_{k \,:\, x_k \leq x} {X = x_k}\right) = \sum_{k \,:\, x_k \leq x} P(X \leq x_k) = \sum_{k \,:\, x_k \leq x} p_X(x_k)
                .\end{align*}
                \item Per il punto (b) dell'Osservazione~\ref{obsv:Funzione_ripartizione} segue che: \[
                    F_X(x_k) - F_X(x_{k-1}) = P(x_{k-1} < X \leq x_k)
                ;\] se i punti di $S$ sono numerati come nell'ipotesi $h < k \implies x_h < x_k$ allora otteniamo: \[
                    P(x_{k-1} < X \leq x_k) = P(X = x_k) \coloneqq p_X(x_k)
                .\]
            \item Riprendiamo l'ipotesi $P(X \in S) = 1$:
                \begin{align*}
                    P(X \in B) &= P(X \in B \cap S) \\
                               &= P\left(\bigcup_{k\,:\,x_k \in B \cap S} \{X = x_k\}\right) = \sum_{k\,:\,x_k \in B \cap S} P(X = x_k) = \sum_{k\,:\,x_k \in B \cap S} p_X(x_k)
                .\qedhere
                \end{align*}
            \end{enumerate}
        \end{proof}
        \begin{obsv}
            Sia $S = \{x_k\,:\,k \in I \subset \mathbb{Z}\} \subset \mathbb{R}$; una funzione $p\,:\, \mathbb{R} \mapsto \mathbb{R}$ è una densità discreta su $S$ se essa soddisfa gli assiomi $(1)$ e $(2)$  della Proprietà~\ref{prty:Densità_discreta}.
        \end{obsv}
    \section{Densità notevoli}
        \subsection{Binomiale}
            \begin{defn}\label{defn:Densità_Binomiale}
                Definiamo la variabile aleatoria $X$ come il numero di successi ottenuti in $n$ prove di Bernoulli; tale variabile aleatoria potrà assumere solamente i valori $0,\, \ldots,\, n$ (è una variabile aleatoria discreta).
                La sua densità vale:
                \begin{equation}\label{eq:Densità_Binomiale}
                    p_X(k) = P(X = k) = \begin{cases}
                        \binom{n}{k}\cdot p^k\cdot (1-p)^{n-k} & \text{se $k \in {0,\, \ldots,\, n}$;}\\
                        0 & \text{se $k \notin {0,\, \ldots,\, n}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Binomiale} \textit{densità binomiale di parametri $n$ e $p$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{B}i(n,\,p)
                .\]
            \end{defn}
            \begin{defn}\label{defn:Densità_Bernoulliana}
                Consideriamo una variabile aleatoria con densità binomiale $X \sim \mathcal{B}i(n,\,p)$ dove $n = 1$; questa variabile rappresenta il numero di successi in una sola prova, ovvero $X \in {0,\, 1}$ e la sua densità vale:
                \begin{equation}\label{eq:Densità_Bernoulliana}
                    \begin{cases}
                        1-p & \text{se $k=0$;} \\
                        p & \text{se $k=1$;} \\
                        0 & \text{se $k \notin {0,\, 1}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Binomiale} \textit{densità bernoulliana di parametro $p$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{B}e(p)
                .\] 
            \end{defn}
            \begin{obsv}
                La variabile aleatoria costante di valore 1 si indica come una variabile aleatoria con densità bernoulliana di parametro 0 ($X \equiv 0 \implies X \sim \mathcal{B}e(0)$); la variabile aleatoria costante di valore 0 si indica come una variabile aleatoria con densità bernoulliana di parametro 1 ($X \equiv 1 \implies X \sim \mathcal{B}e(1)$).
            \end{obsv}
        \subsection{Geometrica}
            \begin{defn}
                Definiamo la variabile aleatoria $X$ l'istante di tempo discreto in cui si verifica un evento, e tale evento sia indipendente dal tempo al quale si verifica; fissato un istante di tempo $k$ possiamo scrivere: \[
                    \forall k \in \mathbb{N} \,:\, P(X > k + 1 | X > k) = P(X > 1)
                .\] Se conosciamo la probabilità $q \coloneqq P(X > 1)$ possiamo ottenere la densità di $X$; usiamo \eqref{eq:Formula_probabilità_condizionata} per riscrivere $q$: \[
                    \forall k \in \mathbb{N} \,:\, q = P(X > 1) = \frac{P(X > k + 1 \cap X > k)}{P(X > k)} = \frac{P(X > k + 1)}{P(X > k)}
                .\] Ora invertiamo la precedente in questo modo:
                \begin{align*}
                    \forall k \in \mathbb{N} \,:\, P(X > k + 1) &= P(X > 1) \cdot P(X > k) \\
                                                        &= P(X > 1)^{k+1} = q^{k+1}
                .\end{align*}
                Sapendo che la funzione di ripartizione di $X$ vale $F_X(k) = 1 - P(X > k) = 1 - q^k$, possiamo ottenere la densità usando il punto $(4)$ della Proprietà~\ref{prty:Densità_discreta}: \[
                    P(X = k) = F_X(k) - F_X(k-1) = q^{k-1} - q^k = q^{k-1}(1-q)
                .\] Definendo l'\textit{intensità di guasto} come la quantità $p \coloneqq 1-q = P(X \leq 1)$ otteniamo la seguente scrittura della densità:
                \begin{align*}
                    P(X = k) = p \cdot (1-p)^{k-1} & &\forall k \in \mathbb{N}
                .\end{align*}
            \end{defn}
            \begin{obsv}
                Richiamiamo la Definizione~\ref{defn:Serie_geometrica}, e dalla somma della serie geometrica otteniamo: \[
                    P(X \in \mathbb{N}) = \sum_{k=1}^{\infty} P(X = k) = \sum_{k=1}^{\infty} p \cdot (1-p)^{k-1} = p \cdot \sum_{k=0}^{\infty} (1-p)^k = p \cdot \frac{1}{1-(1-p)} = 1
                .\] 
            \end{obsv}
            \begin{defn}
                Dalla precedente osservazione e dalla Definizione~\ref{defn:Densità_discreta} concludiamo che $X$ è una variabile aleatoria con la seguente densità:
                \begin{equation}\label{eq:Densità_Geometrica}
                    p_X(k) = \begin{cases}
                        p \cdot (1-p)^{k-1} & \text{se $k \in \mathbb{N}$;} \\
                        0 & \text{se $k \notin \mathbb{N}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Geometrica} \textit{densità geometrica di parametro $p$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{G}(p)
                .\] 
            \end{defn}
        \subsection{Poisson}
            \begin{defn}
                Consideriamo una variabile aleatoria $X \sim \mathcal{B}i(n,\,p)$ con parametro $n \gg 1$ e parametro  $p \ll 1 \land p \in (0,\, 1)$; definiamo inoltre $\lambda \coloneqq n \cdot p$, il quale non dovrà risultare eccessivamente grande (rispetto a $n$).

                Nelle ipotesi appena dettate, perché con un numero grande $n$ di prove indipendenti, aventi ciascuna probabilità di successo $p$ bassa, si abbia un successo, una condizione fondamentale è il valore di $\lambda$, legato alla densità della variabile aleatoria nel modo seguente: \[
                    X \sim \mathcal{B}i(n,\, \lambda / n)
                .\] La probabilità sottostante si scrive come:
                \begin{align*}
                    P(X = x) &= \binom{n}{k} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n}\right)^{n-k} \\
                             &= \frac{n!}{(n-k)!k!} \cdot \left(\frac{\lambda}{n}\right)^k \cdot \left(1-\frac{\lambda}{n}\right)^{n-k} \\
                             &= \underset{(1)}{\underbrace{\frac{n!}{(n-k)!n^k}}} \cdot \underset{(2)}{\underbrace{\left(1-\frac{\lambda}{n}\right)^{-k}}} \cdot \frac{\lambda^k}{k!}\underset{(3)}{\underbrace{\left(1-\frac{\lambda}{n}\right)^{n}}}
                .\end{align*}
                Analizziamo i tre termini evidenziati, al limite per $n$ grande:
                \begin{enumerate}
                    \item $\lim_{n \to \infty} \frac{n!}{(n-k)!n^k} = 1$;
                    \item $\lim_{n \to \infty} \left(1-\frac{\lambda}{n}\right)^{-k} = 1$;
                    \item $\lim_{n \to \infty} \left(1-\frac{\lambda}{n}\right)^{n} = e^{-\lambda}$.
                \end{enumerate}
                Concludiamo che la densità può essere approssimata nel modo seguente, sotto le nostre ipotesi:
                \begin{align}\label{eq:Approssimazione_Binomiale_Poisson}
                        P(X = k) \simeq \frac{\lambda^k}{k!} \cdot e^{-\lambda} & &k \in \mathbb{N},\, \lambda = n \cdot p
                    .
                \end{align}

                Per $\lambda > 0$ possiamo dire che $X$ è una variabile aleatoria con la seguente densità:
                \begin{equation}\label{eq:Densità_Poisson}
                    p_X(k) = \begin{cases}
                        \frac{e^{-k}\lambda^k}{k!} & \text{se $k \in \mathbb{N}$;} \\
                        0 & \text{se $k \notin \mathbb{N}$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Poisson} \textit{densità di Poisson di parametro $\lambda$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{P}(\lambda)
                .\] 
            \end{defn}
            \begin{obsv}
                Possiamo usare \eqref{eq:Approssimazione_Binomiale_Poisson} per il calcolo approssimato di $P(X = k)$ quando abbiamo:
                \begin{itemize}
                    \item $X \sim \mathcal{B}i(n,\,p)$;
                    \item $n \gg 1$;
                    \item $p \ll 1$.
                \end{itemize}
                In questo modo si evita il calcolo dei coefficienti binomiali per ciascun $k$.
            \end{obsv}
        \subsection{Ipergeometrica}
            \begin{defn}
                Consideriamo una variabile aleatoria $X$ che conta in numero di successi in $n$ prove, con probabilità di successo determinata da $r$ esiti favorevoli e $b$ esiti sfavorevoli; inoltre, ogni prova determina l'estrazione dallo spazio campionario di un $r$ o di un $b$.
                Ricaviamo la seguente considerazione: \[
                    X < \scriptstyle\text{MIN}\textstyle(n,\,r) \land X > \scriptstyle\text{MAX}\textstyle(0,\,n-b) \implies X \in S = \{\scriptstyle\text{MAX}\textstyle(0,\,n-b),\, \scriptstyle\text{MAX}\textstyle(0,\,n-b) + 1,\, \ldots,\, \scriptstyle\text{MIN}\textstyle(n,\,r)\}
                .\] Scegliendo un $k \in S$ possiamo calcolare la densità $P(X = k)$ come casi favorevoli su casi possibili:
                \begin{equation}\label{eq:Densità_Ipergeometrica}
                    p_X(k) = P(X = k) = \begin{cases}
                        \frac{\binom{r}{k} \cdot \binom{b}{n-k}}{\binom{r+b}{n}} & \text{se $k \in S$;} \\
                        0 & \text{se $k \notin S$.}
                    \end{cases}
                \end{equation}
                Chiamiamo la \eqref{eq:Densità_Ipergeometrica} \textit{densità ipergeometrica di parametri $b+r$, $r$ e $n$} o in modo equivalente indichiamo: \[
                    X \sim \mathcal{I}(b+r,\, r,\, n)
                .\] 
            \end{defn}
            \begin{obsv}
                Se il valore $r+b$ è molto grande (tende a $+\infty$) allora la dipendenza tra le prove successive si attenua e, in opportune condizioni, è possibile approssimare una variabile aleatoria $X$ con densità ipergeometrica tramite la densità binomiale: \[
                    X \sim \mathcal{I}(b+r,\, r,\, n) \simeq \mathcal{B}i(n,\, r / (r+b))
                .\] 
            \end{obsv}
    \section{Variabili aleatorie continue}
        \begin{defn}\label{defn:Variabile_aleatoria_continua}
            Consideriamo una variabile aleatoria $X$ definita su uno spazio di probabilità $(\Omega,\,\mathbb{F},\,P)$; essa è chiamata variabile aleatoria \textit{assolutamente continua} se esiste una funzione $f_X\,:\, \mathbb{R} \mapsto \mathbb{R^+}$, che sia integrabile e la primitiva della funzione di ripartizione di $X$; inoltre deve essere possibile scrivere $F_X(x)$ nel modo seguente:
            \begin{equation}
                F_X(x) = \int_{-\infty}^{x} f_X(s)\, ds 
            \end{equation}
            Chiamiamo \textit{densità} di $X$ la funzione $f_X(x)$.
        \end{defn}
        \begin{prty}\label{prty:Variabile_aleatoria_continua}
            Se $f_x(x)$ è la densità di una variabile aleatoria $X$ assolutamente continua, allora possiamo affermare che:
            \begin{enumerate}
                \item $\int_{\mathbb{R}} f_X(x)\, dx = 1$;
                \item se risulta che la primitiva di $f_X(x)$ è la funzione di ripartizione di $X$, allora vale: \[
                        \forall x \in \mathbb{R} \,:\, \exists F^{\prime}_X(x) \implies f_X(x) = F_X^{\prime}(x)
                ;\]
            \item se presi $a,\, b \in \mathbb{R}$ si verifica che $-\infty < a < b < +\infty$, allora vale:
                \begin{align*}
                    P\left(X \in (a,\,b)\right) &= P\left(X \in (a,\,b]\right) = P\left(X \in [a,\,b)\right) = P\left(X \in [a,\,b]\right) \\
                                   &= \int_{a}^{b} f_X(x)\, dx
                .\end{align*}
            \end{enumerate}
            \begin{proof}
                \hfill
                \begin{enumerate}
                    \item $1 = \lim_{x \to +\infty} F_X(x) = \lim_{x \to +\infty} \left(\int_{-\infty}^{x} f_X(s)\, ds\right) = \int_{\mathbb{R}} f_X(s)\, ds$;
                    \item conseguenza del teorema fondamentale del calcolo integrale;
                    \item sapendo che $\forall x \in \mathbb{R} \,:\, P(X = x) = 0$ otteniamo: \[
                        P(X \in (a,\,b]) = P({X \in (a,\,b)} \cup {X = b}) = P(X \in (a,\,b)) + \cancel{P(X = b)} = P(X \in (a,\,b))
                    .\] In modo analogo possiamo dimostrare che vale:\[
                        P(X \in (a\,b)) = P(X \in [a\,b)) = P(X \in [a\,b]) 
                    .\] Consideriamo l'intervallo $(a\,b]$:
                    \begin{align*}
                        P(X \in (a,\,b]) &= P(\{X \in (-\infty,\,b]\} \backslash \{X \in (-\infty,\,a]\}) \\
                                      &= P(\{X \in (-\infty,\,b]\} - \{X \in (-\infty,\,a]\}) \\
                                      &= F_X(b) - F_X(a) = \int_{-\infty}^{b} f_X(x)\, dx - \int_{-\infty}^{a} f_X(x)\, dx \\
                                      &= \int_{a}^{b} f_X(x)\, dx \qedhere
                    .\end{align*}
                \end{enumerate}
            \end{proof}
            \begin{prty}
                Consideriamo il punto $(2)$ della Proprietà~\ref{prty:Variabile_aleatoria_continua}.

                Sia $X$ una variabile aleatoria e $F_X(x)$ la sua funzione di ripartizione; se $F_X(x)$ è continua e derivabile con continuità per ogni $x$ in $\mathbb{R}$ \--- eccetto al più un insieme finito di punti $B \coloneqq \{x_1,\,\ldots,\, x_n\} \subset \mathbb{R}$; allora $X$ è una variabile aleatoria \textit{assolutamente continua} e la funzione $f_X(x) = F^{\prime}_X(x)$, definita $\forall x \notin B$ in modo arbitrario su $B$, è una densità per $X$.
            \end{prty}
            \begin{obsv}
                Consideriamo il punto $(3)$ della Proprietà~\ref{prty:Variabile_aleatoria_continua}.

                Sia $X$ una variabile aleatoria \underline{assolutamente continua} con densità $f_X(x)$ e l'insieme $B \subset \mathbb{R}$ sia tale che $B = B_1 \cup B_2 \cup \dotsm$ dove gli intervalli $B_k,\, k = 0,\,1,\,\ldots$ sono disgiunti; allora otteniamo: \[
                    P(X \in B) = \int_{B} f_X(x)\, dx = \sum_{k=1}^{+\infty} \int_{B_k} f_X(x)\, dx
                .\] 
            \end{obsv}
            \begin{obsv}
                Una funzione $f\,:\, \mathbb{R} \mapsto \mathbb{R}$ è una \textit{densità} su $\mathbb{R}$ se valgono:
                \begin{enumerate}
                    \item $f(x)$ è integrabile e $f(x) \geq 0$, per ogni $x$ in $\mathbb{R}$;
                    \item $\int_{\mathbb{R}} f(x)\, dx = 1$.
                \end{enumerate}
            \end{obsv}
        \end{prty}
    \section{Densità continue notevoli}
        \subsection{Bernoulli}
        \subsection{Binomiale}
        \subsection{Geometrica}
        \subsection{Poisson}
        \subsection{Ipergeometrica}
        \subsection{Uniforme}
        \subsection{Esponenziale}
        \subsection{Normale}
        \subsection{Normale Standard}
        \subsection*{Assenza di memoria di geometrica ed esponenziale}
    \section{Struttura della distribuzione geometrica}
    \section{Valore atteso e varianza}
    \section{Deviazione standard}
    \section{Funzioni di variabili aleatorie}
    \section{Trasformazioni affini di variabili aleatorie}
    \section{Standardizzazione di variabile aleatoria}
    \section{Probabilità della normale standard}
    \section{Disuguaglianza di Chebichev}
    \section{Teorema di De Moivre-Laplace}
        \subsection{Approssimazione normale della binomiale}
        \subsection*{Correzione del continuo}
    \section{Momenti}
    \section{Affidabilità}
        \subsection{Tempi di vita}
        \subsection{Intensità di guasto}
        \subsection{Distribuzione di Weibull}
